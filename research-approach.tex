\chapter{RESEARCH APPROACH}
\label{research-approach}

% three requirements of the proposed authoring paradigm
This chapter describes how we solve the problems encountered by researchers who lack the knowledge of proper provenance to capture for reproducing their research results, and cannot afford the distractions caused and efforts required by existing provenance capture practices. An ontology named PROV-PUB-O has been designed to represent knowledge of proper provenance to capture for reproducible research results. It is described in Section~\ref{sec:ontology} A framework that captures provenance and stores it in PROV-PUB-O is specified in Section~\ref{sec:framework}, which fits any result generated through a sequence of invocations of operations and keeps the requirement of user involvement to the minimum. Finally, an implemented proof-of-concept prototype is described in Section~\ref{sec:prototype} to give an example of an authoring platform that is compliant with the framework.

\section{PROV-PUB-O: a provenance ontology for research publications}
\label{sec:ontology}
This section presents the approach to the creation of an ontology for capturing provenance in the process of preparing research publications. The ontology is divided into two parts. 

The first part --- presented in Section~\ref{subsec:structure} --- describes the structure of a research publication. We base our work on the Document Components Ontology (DoCO), which is one of the Semantic Publishing and Referencing Ontologies (SPAR) \cite{peroni2014semantic}. SPAR focuses a lot on modeling citations and bibliographic references. Four out of the eight ontologies in SPAR deal with citations and bibliographic references. (They are CiTO, the Citation Typing Ontology, FaBiO, the FRBR-aligned Bibliographic Ontology, BiRO, the Bibliographic Reference Ontology, and C4O, the Citation Counting and Context Characterization Ontology.) So SPAR is good for modeling the linkage between publications. 

%why we need to model document structure
In this thesis we focus on the reproducibility of a certain publication, so we do not delve deep into citations and bibliographic references as they have nothing to do with the computational experiments presented in the current publication. We model the structure of a research publication because experimental results must reside somewhere in the publication. Textual elements in the publication provide contextual information and explanation for the reported results. Although these elements are not parts of the process leading to the reported results, they are documentation that help readers to correctly interpret the results, so we include structural elements of research publications in the provenance.

The designing guideline of document structure modeling is to select the minimal set of ontology elements from DoCO and define subclasses and properties to get a small ontology just sufficient for the purpose of describing and locating the reported result (such as figure and table). Descriptions of results include their labels and captions, and locations of results are represented in terms of their containers that are parts of the research publications and document components. Although the many constraints found in DoCO strictly define the meanings of its concepts and the logical relations between them, we avoid as many of them as possible to make the ontology contain less distractions other than its main purpose. For example, we just want to describe Figure X resides in Section Y which is part of Chapter Z which is part of Document W, and we do not include the constraints (and actually a distraction, since it is irrelevant to the main purpose of the ontology) that assert things such as ``sections cannot be back matters or body matters or chapters or ...'' 

The second part --- presented in Section~\ref{subsec:process} --- describes the process leading to the reported results. It is a specialization of the W3C Provenance Ontology (PROV-O) for the use case of research publication preparation. We base the development of PROV-PUB-O on PROV-O because using general provenance ontologies such as PROV-O proves to be an effective way to keep track of the lineage of the source data and the changing processes leading to the final results. 

The goal of the specialization is to make the specialized ontology detailed enough to represent the research result generating process in a reproducible manner and at the same time, general enough to represent provenance of results generated in any possible way. The ontology is able to represent the semantics of each element in the process leading to the reported results unambiguously to enable reproduction of the research results in question. Any provenance graph compliant with the ontology is able to be reviewed to decide whether sufficient provenance has been recorded and whether the results in the graph are reproducible. At the same time, the ontology is designed without any a prior assumption about the research result generating methods. The design follows a method agnostic approach to make the ontology applicable to any means of generating research results.

%PROV-PUB-O is further divided into two smaller ontologies: PROV-PUB-O/S for the structural model and PROV-PUB-O/P for the process model. We divide PROV-PUB-O in this way because we find that PROV-PUB-O/S alone can be used by publishing agents to describe typical research publications. 

%The hypothesis to justify for PROV-PUB-O is that it is more usable than PROV-O in modeling research publication preparation process in the domain of earth science for the purpose of replicating data transformation processes and validating scientific conclusions.

\subsection{PROV-PUB-O/S: publication structure modeling}
\label{subsec:structure}

The development of PROV-PUB-O/S follows the following principles:
\begin{itemize}
	\item Minimalism on classes --- meaning to make the number of constraints to its minimum and only define necessary classes to flatten the learning curve, quicken the prototyping and iterating processes.
	\item Rich on properties --- meaning to have multiple ways of expressing relations among classes, so that users are more likely to find a way that is easy to use for them. To avoid incomplete query results due to multiple ways of relation expression, users can choose to follow one particular way but they are not forced by being given only one way.
	\item Leave the decision for dependencies to the users --- meaning that we do not hard code dependencies to other ontologies which force the users to accept them. We just provide suggestions in documentation and let the users decide whether to accept the suggested dependencies.
\end{itemize}

% where do these principles come from?
These principles are based on intuitions. The first principle, minimalism on classes, is based on the intuition that too many classes confuse the user at the very first moment s/he looks at the ontology. It is even worse if some of these classes bear unfamiliar names to the user and constraints requiring certain expertise in OWL. The user needs to learn the inner logic among the vast number of classes to make sure s/he does not break any rule in the system. Too many classes with too many constraints also make the ontology hard to maintain. Every little change may break the consistency of the whole system. When designing PROV-PUB-O/S, we use only the most commonly accepted words such as chapters and sections for class names, and limit the number of constraints to the minimum. In fact, we do not introduce any intra-class constraints other than super/sub-class hierarchy.

The second principle, rich on properties, is based on the assumption that people have very different ways of saying the relations between class instances. For example, the part-whole relation between a figure B and a publication A may be represented as ``A contains a chapter (that contains a section) that contains B'' or ``A has a figure B''. Some people may prefer swapping the positions of A and B and saying ``B is in A'', so if we force the users to use only one way of saying a certain relation by providing in the ontology only one way of saying it, users are likely to find the ontology very cumbersome to use. This is very different from the situation of having a lot of classes, because each class usually represents a distinct type of things, but properties can provide alternative ways of achieving the same linking among classes. The more the number of classes, the more time it takes to find the right ones to use; the more alternative ways of linking classes, the less time it takes to find a proper way, and the more likely a preferable way is found. In PROV-PUB-O/S, shortcut properties are introduced to allow users to represent for example a figure is in a publication directly, instead of forcing the users to express the same meaning with a figure-section-chapter-publication chain of part-whole relations. 

The third principle, leaving the decision for dependencies to the users, is a natural follow-up of the first principle, because subclassing or equivalent-classing means to force the user who wants to use a certain class in the ontology in question to use another class from another ontology, since instances of the class wanted automatically become also instances of the other class in the other ontology. It is virtually adding more classes, and maybe more constraints along with these classes to the ontology in question. Making small ontologies depend on a much larger ontology exposes the users to the complicated class system of the latter and steepens the learning curve of the small ontology dramatically. In PROV-PUB-O/S, subclassing assertions are only suggested in comments and not included in the ontology source file but put in separate bridging ontologies for the users familiar with the depending ontologies to choose to use.

% how these principles are followed
Rather than starting from scratch, we refer to existing models for document structures to get the common vocabulary to follow. Document structure models such as the Document Components Ontology (DoCO)\footnote{DoCO, the Document Components Ontology: \url{http://purl.org/spar/doco}, accessed on October 10th, 2015} are usually based on structural patterns \cite{di2014dealing} and rhetorical structure theory (RST) \cite{taboada2006rhetorical}.

Here we take DoCO as an example. DoCO defines structural (e.g. block, inline, paragraph, section, chapter, and so on --- meaning what the component looks like) as well as rhetorical (e.g. introduction, discussion, acknowledgements, reference list, figure, appendix, and so on --- meaning what role the component plays in the document) document components.

Figure~\ref{fig:doco} shows the components of DoCO and the respective classes included in these components.
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{doco-architecture.png}
	\caption[Architecture of DoCO]{Architecture of DoCO, the Document Components Ontology}
	\label{fig:doco}
\end{figure}

Structural document component types are closely related to the typesetting of the component contents. For example, if a block of text consisting of a title and several paragraphs is known to be a chapter, then at the time of rendering this block, the title can be made larger, proper font and size can be set for the content paragraphs, and the proper spacing can be set between this block and the blocks previous and next to it. Therefore, each structural document component type is like a class used to label HTML elements, and to be rendered according to class styles defined in Cascading Style Sheets (CSS).

Rhetorical document component types are completely irrelevant to typesetting --- just knowing a block of text is an ``introduction'' has nothing to do with properly formatting it. Rather, rhetorical types focus on the \emph{relations} between document parts, so these types are actually \emph{types of relations}. For example, the ``introduction'' component of a paper is usually a chapter, but theoretically it can be a section or even just a paragraph, leading to very different typesetting options. But just look at how we call this ``introduction'' component -- we call it ``introduction \emph{of} a paper'', i.e., an introduction block is always \emph{of something}. It does not make sense to have a ``floating'' introduction attached to nothing. 

In light of this relational perspective of rhetorical types, we make the following changes from DoCO:

\begin{itemize}
	\item The deo:Introduction (\url{<http://purl.org/spar/deo/Introduction>}) class is changed to the pub:introduction property. The prefix deo expands to http://purl.org/spar/deo/ and stands for The Discourse Elements Ontology\footnote{The documentation of the Discourse Elements Ontology is available at http://www.essepuntato.it/lode/owlapi/http://purl.org/spar/deo/, accessed on October 6th, 2015.}, and the prefix pub is for PROV-PUB-O\footnote{PROV-PUB-O is not officially published yet. It is temporarily hosted at \url{http://orion.tw.rpi.edu/~fulinyun/ontology/prov-pub/}, accessed on October 10th, 2015.}. The class pub:Block is the union of pub:Chapter and pub:Section.
	\item The classes sro:Abstract (\url{<http://salt.semanticauthoring.org/ontologies/sro#Abstract>}), deo:Background, deo:Conclusion, deo:Contribution, deo:Discussion, deo:Evaluation, deo:Motivation, deo:Scenario, doco:RelatedWork, \url{doco:Acknowledgements}, doco:Appendix and doco:Foreword are changed in the same manner as deo:Introduction. The prefix sro expands to  http://salt.semanticauthoring.org/ontologies/sro\# and stands for SALT (Semantically Annotated \LaTeX \cite{groza2007salt}) Rhetorical Ontology\footnote{According to http://lov.okfn.org/dataset/lov/vocabs/sro, accessed on October 9th, 2015, this ontology is still offline. Its namespace domain semanticauthoring.org changed owner and the ontology file is missing.}.
	\item The deo:Caption (\url{<http://purl.org/spar/deo/Caption>}) class is changed to the pub:caption property, whose range is xsd:string (\url{<http://www.w3.org/2001/XMLSchema#string>}).  the namespace xsd expands to \url{http://www.w3.org/2001/XMLSchema#} and stands for W3C XML Schema Definition Language\footnote{The documentation of the W3C XML Schema Definition Language (XSD) is listed at \url{http://www.w3.org/2001/XMLSchema#}, see the links in the ``Normative References'' section, accessed on October 6th, 2015.}.
%	\item The sro:Abstract ($<$http://salt.semanticauthoring.org/ontologies/sro\#Abstract$>$) class is changed to the pub:abstract property, whose domain is pub:Block, and range is pub:Document. The prefix sro expands to \comment{get rid of abstract since it's not relevant to tables and figures.} http://salt.semanticauthoring.org/ontologies/sro\# and stands for SALT (Semantically Annotated \LaTeX \cite{groza2007salt}) Rhetorical Ontology. The prefix doco expands to http://purl.org/spar/doco/, and the prefix dcterms expands to http://purl.org/dc/terms/, meaning DCMI (Dublin Core$^{\textregistered}$ Metadata Initiative) Metadata Terms\footnote{DCMI Metadata Terms: http://dublincore.org/documents/dcmi-terms/}.
%	\item The sro:Background class is changed to the pub:background property, whose domain is (doco:Chapter or doco:Section) and (dcterms:isPartOf some doco:BodyMatter), and range is pub:Document. 
%	\item Classes sro:Conclusion, sro:Contribution, sro:Discussion, sro:Evaluation, sro:Motivation, sro:Scenario are changed in the same manner as sro:Background. Note that these classes are different from sro:Abstract in that they cannot be part of the front matter component of a document.
	%\item The class deo:Acknowledgements \comment{not sure yet.} The prefix deo here expands to http://purl.org/spar/deo/ and stands for the Discourse Elements Ontology\footnote{The Discourse Elements Ontology: http://purl.org/spar/deo}.
\end{itemize}

In addition to the changes above, PROV-PUB-O/S is much smaller than DoCO in its number of classes and free of complicated constraints that may confuse the users, yet expressive enough to describe typical research publications without missing any interesting parts. For example, 
\begin{itemize}
	\item In DoCO there are classes representing paragraphs and sentences, which we do not include in PROV-PUB-O/S because section level location is accurate enough for figures and tables. It is accurate enough to say ``Figure X is in Section Y''. It is probably an overkill to say ``Figure X is in the n-th paragraph of Section Y''. However, we did define a result container class and the users can extend PROV-PUB-O/S by defining subclasses of it to describe application specific result containers.
	\item DoCO also contains a ``figure box'' class to represent the physical space within a document that contains a figure and its caption. Such a fine-grained dissection of a figure is probably not necessary for research publications. It is usually clear enough to say ``Figure X has a caption saying Y'', so we define the pub:caption property to describe the relation between a figure and its caption.
	\item A doco:Section can only contain (represented by the pattern:contains property in DoCO: \url{<http://www.essepuntato.it/2008/12/pattern#contains>}) some doco:Paragraph or doco:Section instances, so if we want to express that ``a section contains a figure'' with DoCO, we must be knowledgeable enough to avoid using the pattern:contains property that comes with DoCO but to use a less strict property such as dcterms:hasPart (\url{<http://purl.org/dc/terms/hasPart>}). This is an example showing the confusion caused by complicated constraints. Obviously the constraint is defined without considering the need to locate a figure at the section level. In PROV-PUB-O/S, ``a section/chapter/publication has certain figures'' is expected to be asserted frequently, so the pub:hasFigure property is introduced to make this kind of assertions really easy to make. A reminder of not asserting pub:hasFigure to be a sub-property of pattern:contains is given in the rdfs:comment (\url{<http://www.w3.org/2000/01/rdf-schema#comment>}) annotation to stop users from committing the error. 
\end{itemize}
This follows the principles of minimalism on classes and rich on properties.

Details of the the resulting PROV-PUB-O/S ontology\footnote{PROV-PUB-O/S is not officially published and is temporarily hosted at \url{http://orion.tw.rpi.edu/~fulinyun/ontology/prov-pub/prov-pub-s.ttl}, accessed on October 10th, 2015.} can be found in Chapter~\ref{ch:ontologies}.

%The general hypothesis to justify here is that PROV-PUB-O/S are more usable than DoCO for the task of describing the structure of a research publication, and a specific hypothesis is that properties in PROV-PUB-O/S are more usable than their corresponding rhetorical concepts in DoCO for describing publication components. We conducted user survey to collect opinions about pairs of RDF statement groups such as
%\begin{quote}
%	\begin{tabular}{l}
%	abs a Section;\\
%	 \hspace{1em}isAbstractOf article.\\
%	 \hspace{3em}vs.\\
%	abs a Abstract;\\ 
%	 \hspace{1em}isPartOf article.
%	\end{tabular}
%\end{quote}
%, that is, whether it is better to describe the relation between an article and its abstract component by saying that ``that section is the abstract of the article'' or that ``that section is an abstract, and it is part of the article''. Here we omit all the RDF prefixes in the statements emphasize the modeling rationale.

\subsubsection{Lessons learnt}
The three principles of designing a usable ontology --- minimalism on classes, rich on properties and leaving the decision for dependencies to the users --- is developed as we had finished the conceptual modeling and started writing the ontology in Turtle format, which was considered just a ``finishing up'' work. Documentation requires numerous decisions to make about wordings, definitions or even formatting. The workload increases quickly with the number of classes and dependencies in the form of subclassing or equivalent-classing. One change may trigger a whole lot of change all over the ontology to keep it consistent.

Online and standalone tools are helpful in decreasing the amount of manual work in creating and formatting ontology files and creating documentation. EasyRdf\footnote{EasyRdf converter: http://www.easyrdf.org/converter, accessed on October 10th, 2015.} was used to convert ontologies in RDF/XML format to Turtle format. rdfEditor\footnote{rdfEditor: https://bitbucket.org/dotnetrdf/dotnetrdf/wiki/UserGuide/Tools/rdfEditor, accessed on October 10th, 2015.} was used to edit and validate the ontology files. Make sure to end each namespace properly with a slash (`/') or hash (`\#') character, since editors do not check for errors of this kind, and namespaces not properly ended would yield incorrect IRIs such as \url{<http://purl.org/ontology/biboDocument>} instead of \url{<http://purl.org/ontology/bibo/Document>}. LODE\footnote{Live OWL Documentation Environment: http://www.essepuntato.it/lode, accessed on October 10th, 2015.} was used to generate the draft of documentation for the ontologies. HTML Formatter\footnote{Free HTML Formatter: http://www.freeformatter.com/html-formatter.html, accessed on October 10th, 2015.} was used to format the draft documentation generated by LODE.

\subsection{PROV-PUB-O/P: Result generating process modeling}
\label{subsec:process}
Results in research publications often are quite separated from the underlying collection, transformation and analysis of data. The goal of keeping track of provenance is to enable the readers to understand the process the authors have gone through to produce the reported results from the collected data.

Provenance describes the lineage of the source data and the changing processes leading to the final results for readers to correctly interpret report content. Provenance also enables readers to evaluate the credibility of the reported results by digging into the software in use, operations that have been taken, source data and responsible agents.

Using general provenance ontologies such as PROV-O\footnote{PROV-O: The PROV Ontology: http://www.w3.org/TR/prov-o/, accessed on October 22nd, 2015.}, the new W3C standard adopted in 2013, proves to be an effective way to keep track of the lineage of the source data and the changing processes leading to the final results.

However, in a specific domain of interest, a lot more contextual and operational information that the readers really care about could be added to RDF graphs created with such general ontologies to include much more operationally meaningful elements for automated processing of the provenance graphs.

\subsubsection{Example of direct use of PROV-O to record provenance}
PROV-O\footnote{Lebo, T., Sahoo, S., \& McGuinness, D. (2013). PROV-O: The PROV Ontology. Accessible at: http://www.w3.org/TR/prov-o/, accessed on October 22nd, 2015.} is a great advance based on its predecessors such as Proof Markup Language (PML) \cite{da2006proof} and the Open Provenance Model (OPM) \cite{moreau2011open}, Table 2 in \cite{ma2014ontology} gives a comparison of classes and properties of these three ontologies, which is shown in Table~\ref{tab:comparison}. From the table we see that PROV-O filled in the blanks that are not established in PML and OPM. More classes and properties in PROV-O do not cause the ontology to be more complicated to understand because all these ontological elements are well organized into a simple framework shown in Figure~\ref{fig:prov-o}.
\begin{table}
	\centering
\caption{Similar classes and properties in PROV-O, OPM and PML}
\label{tab:comparison}        % \label command must always comes AFTER the caption
\begin{tabular}{|p{0.07\textwidth}|p{0.31\textwidth}|p{0.31\textwidth}|p{0.31\textwidth}|}
	\hline  & PROV-O & OPM & PML \\ 
	\hline Class-es & prov:Entity & opmv:Artifact & pmlj:Nodeset \newline (+pmlp:Information) \\ 
	  & prov:Activity & opmv:Process & pmlj:InferenceStep \newline (+pmlp:InferenceRule) \\ 
	  & prov:Agent & opmv:Agent & pmlp:InferenceEngine \\ 
	  & prov:Role & opmo:Role & Not established \\ 
	\hline Prope-rties & prov:used & opmv:used & pmlj:hasAntecedentList \newline (+pmlj:NodeSetList) \\ 
	  & prov:wasGeneratedBy & opmv:wasGeneratedBy & pmlj:isConsequentOf \\ 
	  & prov:wasAssociatedWith & opmv:wasControlledBy & pmlp:hasInferenceEngine \\ 
	  & prov:wasAttributedTo & Not established & Not established \\ 
	  & prov:wasDerivedFrom & opmv:wasDerivedFrom & Not established \\ 
	  & prov:wasInformedBy & opmv:wasTriggeredBy & Not established \\ 
	  & prov:actedOnBehalfOf & Not established & Not established \\ 
	  & prov:startedAtTime & opmv:wasStartedAt & Not established \\ 
	  & prov:endedAtTime & opmv:wasEndedAt & Not established \\ 
	\hline 
\end{tabular}
\end{table}
\begin{figure}
	\centering
	\includegraphics[width=0.7\textwidth]{prov-o.png}
	\caption{PROV-O framework}
	\label{fig:prov-o}
\end{figure}
For example, Figure~\ref{fig:gcis} shows what a typical provenance graph fragment looks like if it is created by reusing PROV-O.
\begin{figure}
	\includegraphics[width=\textwidth]{gcis-prov.png}
	\caption{Provenance graph fragment encoded in PROV-O}
	%\comment{to delete the caption inside the figure}
	\label{fig:gcis}
\end{figure}
The example is drawn from the Global Change Information System: Information Model and Semantic Application Prototypes (GCIS-IMSAP) project\footnote{Global Change Information System: Information Model and Semantic Application Prototypes: http://tw.rpi.edu/web/project/gcis-imsap, accessed on October 22nd, 2015.}. The project models and captures provenance information for the recent National Climate Assessment (NCA) draft report\footnote{The full draft for public review is available at http://downloads.globalchange.gov/nca/nca3-drafts/NCAJan11-2013-publicreviewdraft-fulldraft.pdf, accessed on October 22nd, 2015.} of the US Global Change Research Program (USGCRP).

From the provenance graph, we get the information that the paper ``paper/103'' was derived from the dataset ``dataset/103'', which in turn was derived from the dataset ``dataset/TOPEX-POSEIDON'', which was generated by the activity ``activity/.../TOPEX-POSEIDON'' that used the platform ``platform/TOPEX-POSEIDON''. The \emph{protocol} and \emph{domain} URI parts are omitted in the graph to shorten the URI for each node. Also note that all PROV-O properties use past tense verbs to emphasize that everything recorded in the provenance graph must be something that already happened.

Such information is quite useful for the general public to know the process of generating the reported results in the paper. However, for domain scientists who would like to verify the reported results or to base their new research on the work reported in this paper, the provenance graph is short on critical details such as:
\begin{itemize}
	\item How the reported results in ``paper/103'' were derived from ``dataset/103'', e.g., what data items were used to create a certain plot in the paper.
	\item How ``dataset/103'' was derived from ``dataset/TOPEX-POSEIDON'', e.g., what changes were made on what part of the original dataset to generate the derived one.
	\item How ``activity/.../TOPEX-POSEIDON'' used ``platform/TOPEX-POSEIDON'' to generate ``dataset/TOPEX-POSEIDON'', e.g., whether an algorithm and/or a model was used to deal with the raw data from the platform, what parameter values were used to run the algorithm and/or model.
\end{itemize} 
We define our provenance ontology for research publications, called PROV-PUB-O/P, by specializing the ``activity'' class and the ``used'' property in PROV-O to make the ontology suitable for capturing executable provenance in research publications.

Note that ``wasDerivedFrom'' do not need to be specialized because ``e1 wasDerivedFrom e2'' is a shortcut for ``a1 used e1; a1 generated e2'', where e1, e2 are PROV-O entities and a1 is an PROV-O activity. Neither do ``wasGeneratedBy'' since how an activity used its input entities already contains all the information needed for replicating the generation. The property ``wasGeneratedBy'' merely points out the output entity of the activity.

Interesting activities in the process of preparing research papers are all the changes of data, which can be classified into the following three categories:
\begin{itemize}
	\item Physical changes such as data download, copying, or sharing.
	\item Syntactical changes such as XML to JSON conversion.
	\item Semantical changes such as data analysis and transformation.
\end{itemize}
Each of the above changes corresponds to a certain way of data usage.

To capture these changes of data, four classes are defined in PROV-PUB-O/P: pub:DataGeneration for the general changes of data, pub:PhysicalChange for physical changes that keep data ``as is'' and only change the locations and access permissions of data, pub:SyntacticalChange for syntactical changes that keep the logical content of data intact and only change the formats and encodings of data, and pub:SemanticalChange for semantical changes that change the actual logical content of data. For most of the changes of data, it is the semantical changes that are of interest. If all these changes are marked and later queried, it would provide quite useful information of the published result generation process. However, physical changes and syntactical changes can also be critical for certain use cases. The case study we conducted on the 5 figures and 3 tables in Chapter 4 of NCA 2014 report (see Chapter~\ref{ch:case-study} for details) showed that where the authors downloaded their source data and in what way the data were serialized play important roles in fully capturing the provenance of these figures and tables. In the cases where data analysis and transformation are straightforward or standardized, natural language descriptions of semantical changes could take the place of fully fledged source code containing pub:SemanticalChange activities, but the descriptions of the download and syntactical manipulation steps are easily overlooked and often insufficient for reproducing the published results. 

%To further define specialized activities under and beyond the above three categories, we performed a case study on the 5 figures and 3 tables in Chapter 4 of the National Climate Assessment Report published in 2014 (NCA 2014). 

\subsubsection{The common generating process of published results}
Based on the case study on the figures and tables in Chapter 4 of the NCA 2014 report, we summarized the following five common stages of result generation:
\begin{enumerate}
	\item The data obtaining stage, where data hosted by servers or data portals get queried, sliced, filtered and downloaded to get ready for a direct loading to the main memory for the next processing steps. For example, a data file in XML format on a data portal is first downloaded from a data portal, then certain data chunks are extracted from the XML file and saved to a CSV file, ready for the read.csv() function in R to load the data into memory. This whole process is called data obtaining in this thesis. This stage is easily missing in the provenance of a published result, leaving the readers wonder how the authors get their data ready for the claimed processing steps.
	\item The data loading stage, where data serialized and stored on computer hard disks get loaded into the computer memory. These serialized and stored data are different from data already loaded in memory as atomic values or data structures that are held by variables managed by software agents. This stage get the data ready for all the flexible operations only limited by the software agents' capabilities. Source data could be stored in triple stores, databases, local files or files hosted on Websites. For example, the invocation of the read.csv() function in R programming language to get the initial in-memory data object (for further processing) composes the data loading stage. Data do not need to be loaded into memory all at once. For example, a program may read from a data file in a line-by-line manner and process each line and write the processing result to a output file. This is equivalent to loading the data all at once as a vector (list) of lines, apply a certain operation on each element of this vector (such as with the sapply function in R) and write the whole processed vector to the output file. Programs written in either load-all-at-once or part-by-part manner can be easily converted to one another.
	\item The data changing stage, where software agents change in-memory data objects semantically to get the target data objects, ready for presenting in the publication. This stage may contain several sub-stages where previous ones produce source data for the latter ones to load and further process. For example, data loaded with the read.csv() function are processed with various functions provided by different libraries, the data may get sliced, filtered, mapped, and so on. to become a proper data structure in R ready for a plot function. The whole process transforming the data object obtained by the read.csv() function all the way to the data object ready to be passed to a plot function to produce a figure in the publication is the data changing stage. All the semantical changes happen in the memory, although intermediate data objects may be saved to disk at certain points and loaded later from the disk again. This stage is usually considered the only interesting one that worth noting down as the provenance.
	\item The result generation stage, where in-memory data objects are visualized or summarized with certain software agents to generate the results in the publication. Results could be in the forms of figures, tables, lists or textual descriptions. Results are different from both data and source data. Results are saved on computer hard disks, but different from source data, they are not meant to be loaded into memory again, but are for human beings to view in the publication, and the transformation from data to results is non-reversible in the sense that results cannot be transformed as data are transformed to produce new data objects or new results. They, as the name indicates, are the final ``results''. We do not change an existing result to get a new one, rather, we change the data the result is based on in a new way to produce a new result. This stage is usually not sufficiently described, most of the time with only a single word ``plot''.
	\item The result reusing stage, where published results get reused by successive publications. The provenance of the reused result is the same as the original result up till the end of the data changing phase. The differences come from different parameters of the plot function(s) in the result generation stage and/or direct image-level edits on the figure such as scaling and white balance adjustment. The reused result often has substantial similarity with the original result. For example, in our case study we found that Figure~4.1 in NCA 2014, ``Paths of Hurricanes Katrina and Rita Relative to Oil and Gas Production Facilities'', is just a slight adaptation of Figure~3 in the ``Natural Gas: Factors Affecting Prices and Potential Impacts on Consumers (GAO-06-420T)'' report. Both figures are generated with the same data that have come through the data changing stage. 
\end{enumerate}
We recognized three categories of changes of data earlier in this thesis. In the common process of data changes, physical and syntactical changes are performed on on-disk data to generate some other on-disk data, except the last activity that loads the on-disk data into memory, which is both a physical change and a syntactical change. Semantical changes could only happen in memory, although their generated data could be either in-memory or on-disk. If the generated data are saved on disk, then the activity would also be a physical change and a syntactical change. Result generation and reusing are two activities that use data or preexisting results to generate results. In PROV-PUB-O/P, result generation and reusing are not subclasses of data change since we distinguish data from published results and we want to make sure that a change of data always generates data only. 

The three categories of changes of data (physical, syntactical and semantical) are intended to be used to label data changing activities in a domain and application independent way. When we defined more data changing activities, we tried to use the words that keep the ontology domain and application independent to the greatest extent. However, biases coming from our knowledge and experience and the case study we have done are inevitable. Commonly agreed vocabularies within a certain community or group are expected to be introduced as extensions to PROV-PUB-O/P.

Details of the the resulting PROV-PUB-O/P ontology\footnote{PROV-PUB-O/P is not officially published and is temporarily hosted at \url{http://orion.tw.rpi.edu/~fulinyun/ontology/prov-pub/prov-pub-p.ttl}, accessed on October 10th, 2015.} can be found in Chapter~\ref{ch:ontologies}.

\subsection{Reproducibility checking}
Given a provenance graph in PROV-PUB-O, tracing the generation process of a published result corresponds to following the alternating \emph{was generated by} and (a sub-property of) \emph{used} edges from the result node in the graph, and checking the code and descriptions of each node to evaluate its reproducibility if it is an entity node, or its executability if it is an activity node. An entity is reproducible in two situations: either it is not generated by any activity and described sufficiently without any ambiguity on what it is, or the recursive tracing of its generation process shows it is reproducible. Whether an activity is executable depends on two factors: whether itself is sufficiently described with properties such as (programming) \emph{language}, \emph{code} and \emph{description}, and whether all the entities it used are reproducible. 

Figure~\ref{fig:prov-pub-example} shows a sample usage of PROV-PUB-O/P to describe the generation process of a figure very similar with Figure~4.2 in NCA 2014. The obtaining operation, ``:obtain\_data'', generated the on-disk data, ``:csv\_file''. The details of how the data were obtained are described in the textual description, ``dct:description'' of the activity. Then the loading operation, ``:load\_data'', loaded the on-disk data into memory as an in-memory data object, ``csv\_content'', which was then transformed by the transformation operation, ``:transform\_data'', to generate data ``:percent'', which were ready for the visualization operation, ``:plot\_data'', to visualize and generate the published result in the form of a figure: ``:figure4\_2''. 

\begin{figure}
	\centering
	\includegraphics[height=\textheight]{model/ontology/prov-pub/prov-pub-example-bigger.png}
	\caption{Illustrated sample provenance graph in PROV-PUB-O}
	\label{fig:prov-pub-example}
	%\comment{to replace this figure with a more developed one}
\end{figure}

In Figure~\ref{fig:prov-pub-example}, the reproducibility of :figure4\_2 could be reviewed by looking at :plot\_data and checking if it is executable since it is an activity, then looking at :percent and checking if it is reproducible since it is used by the :plot\_data activity. The tracing would go on until we reach entities that was not generated such as :pandas, and activities that did not use any entities such as :obtain\_data.


%The hypothesis we would like to justify here is that sub-properties of prov:used are more usable than prov:used itself in the use case of creating executable provenance graphs in the domain of earth science.

%\subsubsection{Workflow vs. provenance semantics}

%\subsubsection{Executable provenance graphs}

%\subsubsection{Ontology as software}

\subsection{Ontology usability evaluation approach}
\label{subsec:evaluation}
%\comment{We need to find a recurring scientific data analytics task as our use case. Then analyze the pros and cons of using general and specialized provenance ontologies.}

A substantial part of this section comes from an unpublished article I collaboratively authored with Xiaogang Ma and Patrick West \cite{fu2015ontology}.

% why we need ontology usability evaluation
PROV-PUB-O is a specialization of PROV-O. The goal of such kind of specialization, in general, is to create more usable, rather than more useful, systems. The difference between {\em usefulness} and {\em usability} will be detailed later. Here we provide this example first: some touch screen input keyboard includes a ``.com'' key to make inputting website URLs and email addresses more convenient. Adding the ``.com'' key to the keyboard already containing the ``.'' (dot), ``c'', ``o'' and ``m'' keys does not make it more useful, but more usable. In other words, the keyboard, as an input system, does not get functionally more capable by adding the ``.com'' key, but becomes practically more convenient and pleasant to use for people who need to input dot com website URLs and email addresses belonging to the dot com domain. Note that usability is always related to users with certain tasks to accomplish. For some users, keyboards with a ``.com'' key are more useful than those without, for other users, this may not be true because they never need to input ``.com'': they may instead need to input ``.edu'' a lot, and feel the ``.com'' keyboard the same as the normal one or even cumbersome to use because of the presence of a large but useless key.

% useful and usable
We claim that PROV-PUB-O is more usable to research publication authors than PROV-O. Therefore, to justify that the creation of PROV-PUB-O is indeed a contribution, we need a set of criteria for the evaluation of ontology usability, through which people will be able to describe and assess an ontology from different aspects. The items in the criteria, however, are decided by the understandings about the meaning of \emph{usability}. We adopt the definition given in the international standard ISO 9241-11 \cite{iso19989241}, which has received endorsements from various domains: ``[Usability is] the extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency and satisfaction in a specified context of use.'' The background of this definition is Human-Computer Interaction and the definition represents a user-centered point of view \cite{jokela2003standard}. The definition indicates that usability is not about the product itself (or, its quality), but about the activity of a user using it, so usability depends on the goal of the user and the context of the use. With satisfaction as one of its attributes, defined as ``freedom from discomfort, and positive attitude to the use of the product'' \cite{iso19989241}, usability is inevitably subjective.

Therefore, existing criteria for assessing quality of ontologies do not necessarily fit in ontology usability evaluation. Although some of them can serve as strong usability indicators. For example, Gruber \cite{gruber1995toward}
discussed several elements for ontology design: clarity, coherence, extendibility, minimal encoding bias, and minimal ontological commitment, which are all good principles for ontology quality evaluation, but to do usability evaluation, Fox and Lynnes added a few other items, namely contextual relevance, maturity, intended use, and fitness for use, to Gruber's list to cover the contextual and subjective aspects of ontology usability\footnote{Additional items for ontology evaluation. \url{http://tw.rpi.edu/web/project/SeSF/workinggroups/OntologyEvaluation}, accessed on September 9th, 2015.}.

In this thesis we define the Ontology Usability Scale (OUS) for the evaluation of ontology usability. The evaluation metrics are reflected in a short list of statements, which were derived from an online poll in the Semantic Web community. We will introduce our thoughts on semiotics when preparing a long list of statements for the poll, and will also analyze the community's concerns on ontology usability by using the outputs of the poll.

\subsubsection{Related work on ontology evaluation}
% history of ontology evaluation.
Although it is hard to find related work specifically on evaluating ontology usability, the general evaluation of ontologies, however, has already received attention even before the introduction of Resource Description Framework (RDF) \cite{brickley2000resource} and Web Ontology Language (OWL) \cite{mcguinness2004owl}. For example, Gr{\"u}ninger et al. \cite{gruninger1995methodology} proposed a method to check the completeness of an ontology with respect to a set of competency questions. Competency questions are the questions that the ontology is designed to answer, so this method checks whether ``the right things are done'', and does not benefit people who later want to reuse the ontology.

%Nowadays many ontologies are written in Resource Description Framework Schema \cite{brickley2000resource} (RDFS) or Web Ontology Language \cite{mcguinness2004owl} (OWL). The evaluation of ontologies, however, has been paid attention to long before the introduction of these two ontology languages. For example, Gr{\"u}ninger et al in their paper \cite{gruninger1995methodology} proposes a method to check the completeness of an ontology with respect to a set of competency questions. Competency questions are the questions that the ontology is designed to answer, so this approach checks whether ``the right things are done''. Back then, ontologies are defined with first-order logic (or equivalently, in Knowledge Interchange Format (KIF)), so the authors formalized competency questions also with first-order logic and evaluate the ontology in question by proving completeness theorems with respect to these formal competency questions.

With the major Semantic Web standards and heavily reused upper ontologies being available (see Figure~\ref{fig:timeline} for a timeline of Semantic Web standards, and \cite{bikakis2013xml} for the details), representing domain knowledge with ontologies became a common practice and it became more and more likely to see several different conceptualizations of the same domain. Therefore, ontology evaluation methods for the purpose of selecting and reusing existing ontologies for new applications were greatly needed.

\begin{figure}
	\centering
	\includegraphics[height=\textheight]{XMLSemanticWebW3CTimeline.png}
	\caption[XML and Semantic Web W3C standards timeline]{XML and Semantic Web W3C standards timeline}
	\label{fig:timeline}
\end{figure}

A popular approach to do this kind of evaluation is to define several criteria for decision making, evaluate the ontology in question on each criterion by giving a numerical score, and then compute the overall score for the ontology as a weighted sum of the per-criterion scores. Such methods are called multiple-criteria approaches in \cite{brank2005survey}. For example, Fox et al. \cite{fox1995organisation} proposed a set of criteria including generality, completeness, perspicuity, and so on. Gomez-Perez in her paper \cite{gomez2001evaluation} published in 2001 pointed out the lack of interest in evaluation issues in the ontological engineering community at that time. She also pointed out that tools, tutorials and case studies are critical for ontology engineers to assess the usability of an existing ontology. Nevertheless, the paper does not give an example of ontology usability evaluation, it instead evaluates the Standard-Unit Ontology in terms of consistency, completeness and conciseness, so the evaluation result is not directly related to the effectiveness, efficiency and satisfaction of the users when they reuse a certain ontology. An ontology may be consistent (i.e. without any contradictory assertion), complete (i.e. without any missing definition) and concise (i.e. without any unnecessary definition), but still be unusable or very cumbersome to use (e.g. due to bad documentation).

Lozano-Tello et al. presented the ONTOMETRIC method \cite{lozano2003selection,lozano2004ontometric}, which compares ontologies with a taxonomy of 160 characteristics organized in a multi-level tree-shaped framework. At the top level, there are five basic aspects. These are: 
\begin{enumerate}
	\item the \emph{content} of the ontology and the
	organization of their contents, 
	\item the \emph{language}
	in which it is implemented, 
	\item the \emph{methodology}
	that has been followed to develop it,
	\item the software \emph{tools} used to build and edit
	the ontology, and 
	\item the \emph{costs} that the ontology
	will be necessary in a certain project.
\end{enumerate}
The final score for an ontology is calculated as the weighted sum of the scores given to each of the leaf node characteristics, through aggregations at each of the internal nodes governing aspects and sub-aspects of the ontology characteristics. It could be imagined that the scoring and weight assignment would take a lot of time and be easily biased by the viewpoint of the scorer, as pointed out by Hartmann et al. in \cite{hartmann2005d1}. Similar with ONTOMETRIC, our approach also requires a scorer to get a single numerical score for each ontology in question, but we provide the scorer a Likert scale (a questionnaire asking for degrees of agreement with a list of statements) consisting of around 10 items, instead of a huge scoring form with pending weights for each item. We found a small portion of the 160 characteristics directly related to usability, and drew them out as our candidate usability metrics.

%As more and more ontologies became available online (see Figure~\ref{fig:timeline} for a timeline of Semantic Web standards, and \cite{bikakis2013xml} for the details), attention is paid to the evaluation of ontologies for the purpose of selecting an existing ontology to reuse in a new application. A popular way to do this kind of evaluation is to define several criteria for decision making, evaluate the ontology in question on each of them, giving a numerical score, and compute the overall score for the ontology as a weighted sum of its per-criterion scores. This group of approaches is called \emph{multiple-criteria approaches} in \cite{brank2005survey}. For example, Fox et al in \cite{fox1995organisation} proposed a set of criteria including \emph{generality}, \emph{completeness}, \emph{perspicuity}, etc.; G{\'o}mez-P{\'e}rez in her paper \cite{gomez2001evaluation} published in 2001 pointed out the lack of interest in evaluation issues in the ontological engineering community at that time. She also pointed out that tools, tutorials and case studies are critical for ontology engineers to assess the usability of an existing ontology. Unfortunately the paper does not give an example of ontology usability evaluation, it instead evaluates the Standard-Unit Ontology in terms of consistency, completeness and conciseness; Lozano-Tello et al present the \emph{ONTOMETRIC} method \cite{lozano2003selection,lozano2004ontometric}, which compares ontologies with a taxonomy of
%160 characteristics organized in a multilevel framework. At the top level, there are five basic aspects. These are: the \emph{content} of the ontology and the
%organization of their contents, the \emph{language}
%in which it is implemented, the \emph{methodology}
%that has been followed to develop it,
%the software \emph{tools} used to build and edit
%the ontology, and the \emph{costs} that the ontology
%will be necessary in a certain project. For each ontology under consideration, the ONTOMETRIC method basically calculates the weighted sum of the scores given to each of the leaf node characteristics of this tree-shaped framework. Aggregated scores are obtained for sub-tree roots as the calculation ascending each level along the tree, so the final score is finally available at the root node. Hartmann et al in \cite{hartmann2005d1} pointed out the following two usability issues of ONTOMETRIC:
%\begin{itemize}
%	\item Specifying the characteristics of an ontology
%	is complicated and takes time
%	\item Assessing
%	the characteristics is quite subjective (from the
%	project managers' viewpoint)
%\end{itemize} 

Different from the studies mentioned above, Burton-Jones et al. \cite{burton2005semiotic} proposed a set of 10 attributes that fall into four metrics suites (i.e. syntactic, semantic, pragmatic and social quality) of a semiotic frame-work. They tried to find objective indicators to assess each recognized metric to eliminate the need of human reviewers. For example, the \emph{Lawfulness} dimension of the \emph{Syntax} metric is indicated by the percentage of correct syntax per class and property. The authors suggested that the evaluation could be extended to cover application-centered assessment of the quality of an ontology for use in a specific task. We create our list of candidate usability metrics by thinking in the aspects of syntax, semantics and pragmatics. We assume that the difference of social quality (authority and history) between two ontologies would dwarf the
overall impact of these three other aspects. In fact, only ontologies of similar social quality are worth comparing. If one of them has significantly more authority (i.e. more ontologies rely on it) or longer history (i.e. it has been used more), it would be an obvious winner. We also found it hard, if not impossible, to assess some of the important metrics with objective indicators. For example, the quality of documentation is very important to the usability of the ontology, but it is hardly possible to be measured in any objective way, so we argue that it requires the participation of human reviewers to get meaningful usability assessments.

%Different from the studies mentioned above, Burton-Jones et al proposed a set of 10 objective metrics at 4 different levels of a semiotic framework in \cite{burton2005semiotic}. Their work supports objective evaluation of ontologies, which does not require experts' review of the ontologies in questions. 

The semiotic framework was also used in Gangemi et al. \cite{gangemi2006qood}. The authors organized the criteria for ontology evaluation and selection with a semiotic meta-ontology called $O^2$ and the oQual evaluation ontology which involves concepts and relations relevant to ontology evaluation and selection. Therefore, evaluation based on the oQual ontology goes beyond the mere calculation of a weighted sum, but also contains reasoning based on the evaluation ontology. Goals of reusing the ontology and trade-off rules among conflicting goals must be defined formally and in a way that connects with $O^2$ and oQual in order to follow their approach, which limits its application to ontology experts only. The target user group of our metrics is anyone who wants to select an ontology suitable to an application (meaning the user can apply the selected ontology to his/her use case with the most aggregated effectiveness, efficiency and satisfaction among all the candidate ontologies), so we require much less ontological expertise of our users than their approach.

%In \cite{gangemi2006qood}, Gangemi et al organized the criteria for ontology evaluation and selection with a semiotic meta-ontology called $O^2$ and the \emph{oQual} evaluation ontology which involves concepts and relations relevant to ontology evaluation and selection. Therefore, evaluation based on the oQual ontology goes beyond the mere calculation of a weighted sum, but also contains reasoning based on the evaluation ontology. 
%\comment{to read: OntoQA \cite{tartir2005ontoqa} (schema- and instance- level metrics) Ontology metrics design \cite{vrandevcic2007design} Unit tests for ontologies \cite{vrandevcic2006unit}.} 

Casellas \cite{casellas2009ontology} used System Usability Scale \cite{brooke1996sus} to evaluate the usability of the Ontology of Professional Judicial Knowledge (See Chapter 2 of \cite{casellas2009ontology} for an introduction of the ontology). Our approach differs with Casellas' in how we select the statements in the questionnaire. Casellas directly tailored the 10 items in SUS, but we think that the set of statements that best indicate the usability of ontologies may need to consider more aspects. We created a pool of 29 candidate statements by adapting several resources, including those used in \cite{casellas2009ontology}. Then we built the usability scale from those candidate statements through some community efforts, i.e. we gathered preferences among the Semantic Web community through an online poll. The result of the poll verified our thoughts since it differed a lot from the statement set in \cite{casellas2009ontology}.

\subsubsection{Research approach for creating OUS}
The intuition behind our approach to evaluating ontology usability comes from the System Usability Scale (SUS), a ten-item Likert scale whose usage is recommended by the UsabilityNet project as ``it is very robust and has been extensively used and adapted. Of all the public domain questionnaires, this is the most strongly recommended''. We hope to have such a concise scale that is applicable for ontology usability evaluation.

A direct adaptation of SUS for ontology (i.e. replace ``system'' with ``ontology'' in the questionnaire) does not cover all the aspects in our understanding of the ontology usability. Therefore, besides those items adapted from SUS, we collected usability evaluation statements from ONTOMETRIC \cite{lozano2004ontometric} and Casellas' work \cite{casellas2009ontology} to set up a large pool of statements. When collecting those statements we also refer to the semiotic framework discussed in Burton-Jones et al. \cite{burton2005semiotic} and Gangemi et al. \cite{gangemi2006qood}, but our understanding of the syn-tax, semantics and pragmatics is slightly different because in our work the focus is the usability. We consider syntax is relevant to the machine readable encoding and logic of the content of an ontology; semantics is relevant to the conceptual model and documentation; and pragmatics is relevant to the first hand experience of using the ontology in practice. Table~\ref{tab:statements-pool} shows the grouped statements in the large pool. Note that we changed some statements originally in negative forms to positive forms so that all the statements are desired features of a highly usable ontology. Each feature represented by one of the statements can be represented in either the positive form or the negative form. Both forms are found in our original statement set. Two of these statements, numbered 23 and 26 in Table~\ref{tab:statements-pool}, are even in the two forms of exactly the same feature. To eliminate bias caused by the statement representation form and avoid listing the same feature twice (in both positive and negative forms) in the questionnaire, we decided to normalize every statement to its positive form.

\begin{longtable}{p{\textwidth}}
	\caption{The large pool of statements for ontology usability evaluation}
	\label{tab:statements-pool}\\
	\hline
	Syntax (Content)
	\begin{enumerate}
		\item I found the various concepts in this ontology well integrated
		\item The ontology misses some important concepts --- Changed to ``The ontology has all the important concepts included'' in the survey
		\item The ontology has unnecessary concepts --- Changed to ``The ontology does not have unnecessary concepts''
		\item I found the ontology unnecessarily complex --- Changed to ``I found the ontology brief but comprehensive''
		\item I thought there was too much inconsistency in this ontology --- Changed to ``I found the various parts of this ontology well integrated''
		\item I found the formal specification of concepts in this ontology coincides with their descriptions in natural language
		\item I found the formal specification of relations in this ontology coincides with their descriptions in natural language
		\item I think the attributes in this ontology describe the concepts well
		\item I think the relations in this ontology relate appropriate concepts
		\item I found the subclasses in this ontology are properly defined
		\item I found the disjoint classes in this ontology are properly asserted
	\end{enumerate} \\
	\hline
	Semantics (Documentation)
	\begin{enumerate}
		\setcounter{enumi}{11}
		\item The purpose of this ontology is clear
		\item I am confident I understand the conceptualization of the ontology
		\item I need to ask a lot of questions before I could understand the conceptualization of the ontology --- Changed to ``I could understand the conceptualization of the ontology without asking a lot of questions''
		\item I find the ontology easy to understand
		\item The annotations are helpful
		\item I found the concepts in this ontology properly described in natural language
		\item I found the relations in this ontology properly described in natural language
		\item I need further theoretical support to understand this ontology --- Changed to ``I do not need further theoretical support to be able to understand this ontology''
		\item I would imagine that most domain experts would understand this ontology very quickly
	\end{enumerate} \\
	\hline
	Pragmatics (First-hand experience)
	\begin{enumerate}
		\setcounter{enumi}{20}
		\item I would imagine that most people would learn to use this ontology very quickly
		\item I needed to learn a lot of things before I could get going with this ontology --- Changed to ``I do not need to learn any extra things before I could get going with this ontology''
		\item I thought the ontology was easy to use
		\item It is clear to me how to use this ontology
		\item I felt very confident using the ontology
		\item I found the ontology very cumbersome to use --- Deleted in the survey since it is the negative form of statement 23 and we decided to present all the statements in their positive forms only.
		\item I think that I would need the support of a person experienced with this ontology to be able to use it --- Changed to ``I do not need the support of a person experienced with this ontology to be able to use it''
		\item I need some more examples than provided in the documentation to make sure how to use the ontology --- Changed to ``I think the documentation provides sufficient examples for me to make sure how to use the ontology''
		\item I think that I would like to use this ontology frequently
		\item I think that I could contribute to this ontology
	\end{enumerate} \\
	\hline
\end{longtable}
The long list of statements provides a comprehensive usability evaluation, but the burden caused by the number of statements can be an issue. Our goal is to reduce the number of statements in the final evaluation form to around 10 so that the form could be quickly filled out and more people are likely to be willing to participate in the evaluation. To achieve this goal, we gathered opinions from ontology users and developers by reaching out to the semantic web community to ask for a poll for selecting 10 representative statements. We sent out invitations to the semantic web working group of the Federation of Earth Science Information Partners, the semantic web group on Facebook, and also colleagues at Tetherless World Constellation at Rensselaer Polytechnic Institute. To avoid confusion in reading the statements, we changed the forms of a few of them (see notes in Table~\ref{tab:statements-pool}) to make all the statements have a positive form, i.e. towards the goodness of an ontology instead of shortcomings. Moreover, we mixed the sequence of those statements in the survey and did not show the three groups of syntax, semantics and pragmatics of those statements in order to avoid any bias that may be led to the survey participants. We received 18 valid responses in 7 days, and the top 11 statements from the poll and the votes they each received are shown in Table~\ref{tab:poll}.
\begin{table}
	\centering
	\caption{The top 11 statements resulted from an online poll and the votes to each statement received}
	\label{tab:poll}
	\begin{tabular}{|p{0.06\textwidth}|p{0.62\textwidth}|p{0.13\textwidth}|p{0.06\textwidth}|}
		\hline Num-ber & Statement & Category & Votes \\ 
		\hline 1 & I think the documentation provides sufficient examples for me to make sure how to use the ontology. & Pragmatics & 14 \\ 
		\hline 2 & The purpose of this ontology is clear. & Semantics & 9 \\ 
		\hline 3 & I found the concepts in this ontology properly described in natural language. & Semantics & 9 \\ 
		\hline 4 & I think the relations in this ontology relate appropriate concepts. & Syntax & 8 \\ 
		\hline 5 & I am confident I understand the conceptualization of the ontology. & Semantics & 8 \\ 
		\hline 6 & I would imagine that most domain experts would understand this ontology very quickly. & Semantics & 7 \\ 
		\hline 7 & I think the attributes in this ontology describe the concepts well. & Syntax & 7 \\ 
		\hline 8 & I found the subclasses in this ontology are properly defined. & Syntax & 7 \\ 
		\hline 9 & I found the relations in this ontology properly described in natural language. & Semantics & 7 \\ 
		\hline 10 & I found the formal specification of concepts in this ontology coincides with their descriptions in natu-ral language. & Syntax & 7 \\ 
		\hline 11 & I do not need the support of a person experienced with this ontology to be able to use it. & Pragmatics & 7 \\ 
		\hline 
	\end{tabular} 
\end{table}
In Table~\ref{tab:poll} we can see that 5 of the top 11 statements are about semantics, 4 for syntax and the left 2 for pragmatics, which is a strong indication that usability of ontology is mostly about semantics and syntax. This also supports our above discussion that the SUS probably would not work well on ontologies because it is mostly about pragmatics.

We compiled our 10-item Likert scale for ontology usability evaluation based on the above result, as shown in Table~\ref{tab:ous-draft}.
\begin{table}
	\begin{center}
		\caption{Ontology usability evaluation questionnaire}
		\label{tab:ous-draft}
		\begin{tabular}{|p{0.1\textwidth}|p{0.62\textwidth}|l|l|l|l|l|}
			\hline Number & Statement & 1 & 2 & 3 & 4 & 5 \\ 
			\hline 1 & I think the documentation provides sufficient examples for me to make sure how to use the ontology. &  &  &  &  &  \\ 
			\hline 2 & The purpose of this ontology is clear. &  &  &  &  &  \\ 
			\hline 3 & I found the concepts and relations in this ontology properly described in natural language. &  &  &  &  &  \\ 
			\hline 4 & I think the relations in this ontology relate appropriate concepts. &  &  &  &  &  \\ 
			\hline 5 & I am confident I understand the conceptualization of the ontology. &  &  &  &  &  \\ 
			\hline 6 & I would imagine that most domain experts would understand this ontology very quickly. &  &  &  &  &  \\ 
			\hline 7 & I think the attributes in this ontology describe the concepts well. &  &  &  &  &  \\ 
			\hline 8 & I found the subclasses in this ontology are properly defined. &  &  &  &  &  \\ 
			\hline 9 & I found the formal specification of concepts and relations in this ontology coincides with their descriptions in natural language. &  &  &  &  &  \\ 
			\hline 10 & I do not need the support of a person experienced with this ontology to be able to use it. &  &  &  &  &  \\ 
			\hline 
		\end{tabular} 
	\end{center}
\end{table}
In Table~\ref{tab:ous-draft}, closely related statements about concepts
and relations were merged together. i.e., statements
3 and 9 in Table~\ref{tab:poll} were merged to ``I found the
concepts and relations in this ontology properly described
in natural language'', and statement 10 was
changed to ``I found the formal specification of concepts
and relations in this ontology coincides with
their descriptions in natural language''. We did this
based on the assumption that concepts are equally
important as and considered together with relations
in an ontology.

A scale from 1 to 5 was used to indicate ``highly
disagree'', ``disagree'', ``neutral'', ``agree'' and ``highly
agree'' against each statement in Table 3, so higher
scores mean better usability. To assess the usability
of an ontology using this form, a scorer needs to give
a score indicating his/her degree of agreement for
each statement, denoted as $s_1$, $s_2$, ..., $s_10$, then the
total score $s_t$ is calculated as
\begin{equation}
\label{eq1}
s_t = \sum_{i=1}^{10}s_i
\end{equation}
, which ranges from 10 to 50.

To further improve the questionnaire, we use positive
and negative forms of statements in Table~\ref{tab:ous-draft} alternately
to make scorers more attentive when they
fill out the form. The adapted and reorganized statements
are shown in Table~\ref{tab:ous}.
\begin{table}
	\centering
	\caption{Recommended ontology usability scale}
	\label{tab:ous}
		\begin{tabular}{|p{0.1\textwidth}|p{0.62\textwidth}|l|l|l|l|l|}
			\hline Number & Statement & 1 & 2 & 3 & 4 & 5 \\ 
			\hline 1 & The purpose of this ontology is clear. &  &  &  &  &  \\ 
			\hline 2 & I need more examples than provided in the documentation to make sure how to use the ontology. &  &  &  &  &  \\ 
			\hline 3 & I found the concepts and relations in this ontology properly described in natural language. &  &  &  &  &  \\ 
			\hline 4 & There is inconsistency between the formal specification of concepts and relations in this ontology and their descriptions
			in natural language. &  &  &  &  &  \\ 
			\hline 5 & I would imagine that most domain experts would understand this ontology very quickly. &  &  &  &  &  \\ 
			\hline 6 & I think that I would need the support of a person experienced with this ontology to be able to use it. &  &  &  &  &  \\ 
			\hline 7 & I am confident I understand the conceptualization of the ontology. &  &  &  &  &  \\ 
			\hline 8 & The attributes in this ontology fail to describe the concepts properly. &  &  &  &  &  \\ 
			\hline 9 & I think the relations in this ontology relate appropriate concepts. &  &  &  &  &  \\ 
			\hline 10 & I think the class hierarchy of this ontology needs better organization. &  &  &  &  &  \\ 
			\hline 
		\end{tabular} 
\end{table}
In Table~\ref{tab:ous}, the statements at odd numbered positions
are all in a positive form and those at even
numbered positions are all in a negative form. To use
this form, Equation~\ref{eq1} needs to be changed to
\begin{equation}
\label{eq2}
s_t = \sum_{i \textrm{ \scriptsize is odd}}s_i+\sum_{i \textrm{ \scriptsize is even}}(6-s_i)
\end{equation}
, which still ranges from 10 to 50. A higher score
indicates a higher usability.
\subsubsection{Case study and evaluation}
\label{sec:prov-pub-eval}
We used the developed OUS, i.e. statements in
Table~\ref{tab:ous} for a case study of ontology usability evaluation
within the Tetherless World Constellation at
Rensselaer Polytechnic Institute. The case study was
carried out as an anonymous online survey, in which
each participant was asked to choose an ontology and
assign a score to each statement. The outputs of the
survey are listed in Table~\ref{tab:ous-case}. Since revisions are currently
undergoing to update the ontologies of Deep Carbon Observatory (DCO) and Global Change In-formation System (GCIS), we will be able to apply the developed OUS to their later versions to check if the revisions are effective in terms of usability. Comparisons among ontologies with similar intended uses and different versions of the same ontology are made easy with OUS since each ontology is given an overall score calculated from the answers given by each reviewer. Scoring an OUS form (Table~\ref{tab:ous}) does not require much of the reviewers' time, but the collected answers provide simple yet comprehensive assessments of the usability of the ontologies in question.
\begin{table}
	\centering
	\caption{Results of ontology usability evaluation in a case study}
	\label{tab:ous-case}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline Ontology & $s_1$ & $s_2$ & $s_3$ & $s_4$ & $s_5$ & $s_6$ & $s_7$ & $s_8$ & $s_9$ & $s_{10}$ & $s_t$ \\ 
		\hline DCO & 5 & 4 & 3 & 2 & 4 & 3 & 5 & 2 & 4 & 2 & 38 \\ 
		\hline DCO & 5 & 4 & 4 & 1 & 3 & 2 & 5 & 1 & 5 & 2 & 42 \\ 
		\hline DCO & 3 & 1 & 4 & 3 & 2 & 2 & 2 & 4 & 3 & 5 & 29 \\ 
		\hline GCIS & 4 & 2 & 4 & 2 & 4 & 3 & 4 & 2 & 4 & 3 & 38 \\ 
		\hline GCIS & 5 & 3 & 4 & 1 & 5 & 2 & 5 & 1 & 5 & 3 & 44 \\ 
		\hline SIO & 5 & 5 & 5 & 2 & 5 & 5 & 2 & 1 & 5 & 3 & 36 \\ 
		\hline VSTO & 1 & 5 & 1 & 3 & 2 & 4 & 4 & 2 & 4 & 2 & 26 \\ 
		\hline 
	\end{tabular} 
\end{table}

Finally, we also used OUS to evaluate PROV-PUB-O, and the results are shown in Table~\ref{tab:eval-pub}.
\begin{table}
	\centering
	\caption{Usability evaluation results for PROV-PUB-O}
	\label{tab:eval-pub}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|}
		\hline \# & $s_1$ & $s_2$ & $s_3$ & $s_4$ & $s_5$ & $s_6$ & $s_7$ & $s_8$ & $s_9$ & $s_{10}$ & $s_t$ \\ 
		\hline 1 & 4 & 2 & 4 & 3 & 2 & 2 & 2 & 3 & 2 & 3 & 31 \\ 
		\hline 2 & 4 & 5 & 3 & 2 & 4 & 5 & 3 & 3 & 5 & 3 & 31 \\ 
		\hline 3 & 4 & 3 & 3 & 3 & 4 & 4 & 5 & 2 & 4 & 3 & 35 \\ 
		\hline 4 & 5 & 2 & 5 & 2 & 2 & 1 & 5 & 1 & 4 & 2 & 43 \\ 
		\hline 5 & 4 & 4 & 3 & 1 & 4 & 2 & 4 & 3 & 4 & 4 & 35 \\ 
		\hline 6 & 2 & 4 & 4 & 3 & 1 & 2 & 4 & 2 & 4 & 2 & 32 \\ 
		\hline 7 & 5 & 3 & 4 & 3 & 5 & 3 & 4 & 2 & 4 & 4 & 37 \\ 
		\hline 
	\end{tabular} 
\end{table}
Invitations to evaluate PROV-PUB-O\footnote{The online survey form is located at \url{https://linyunfu.typeform.com/to/f5dXvI}, accessed on November 23, 2015.} were sent to the semantic web group on Facebook, the semantic web cluster of the Federation of Earth Science Information Partners, the Reproducibility interest group and the Research Data Provenance interest group of Research Data Alliance, and colleagues at Tetherless World Constellation at Rensselaer Polytechnic Institute. Participations are anonymous. We asked the participants to tell us their roles and how long they had been working with ontologies. The highest score came from an ontology developer, data curator, earth and space scientist and software developer with more than 5 years of experience in ontologies. One of the lowest scores was given by the first participant, who is an ontology developer, data curator, scientist in a domain other than earth and space science and software developer with more than 5 years of experience in ontologies. This may indicate that PROV-PUB-O ``overfitted'' the earth and space science domain. They both gave valuable feedbacks, including considering hosting PROV-PUB-O on \url{purl.org} instead of a student's Web folder, reusing concepts already defined in other ontologies, and considering defining pub:Library as a subclass of prov:Plan as the approach of ProvONE.

One participant with only a single role of a domain scientist pointed out that examples in the form of RDF triples may not fit for domain scientists because they do not interact with ontologies in this form and need more operational examples to show them the benefits of adopting the ontology.

\subsubsection{Discussion on OUS}
The resulting ontology usability scale of this study covers topics of syntax, semantics and pragmatics and addresses the issue of evaluating the usability of an ontology in a certain context. The list of statements in the current scale (Table~\ref{tab:ous}) is based on a survey. It has a concise structure and is easy to use in practice. The scale can be used by all stakeholders who participated in the development, application, and revision of an ontology, and the result can be used to improve the ontology.

Semiotics is the study of signs. It is applicable to ontologies because ontologies are sign systems to represent knowledge. The division of semiotics into semantics, syntactics and pragmatics was contributed by Morris \cite{morris1938foundations}. According to Morris, semantics is the study of the relation of signs to the things they refer to (their designata); syntactics is the study of the relation of signs to one another; pragmatics studies the relation of signs to their interpreters. In the case of ontology, we define semantics as the mapping of domain knowledge to ontological elements such as classes and relations, or the meaning of these elements, conveyed through the conceptual model and documentation. Syntactics (or syntax according to Burton-Jones et al. \cite{burton2005semiotic}) is defined as the way the ontological elements are organized, usually with terms in RDFS or OWL. Pragmatics is the relation of ontologies to their users, so it is about the activity of a user using an ontology.

According to the above definitions, it seems only the pragmatical dimension of semiotics is relevant to ontology usability since it is the only dimension about the ontology using activity rather than the ontology itself, and usability is about certain attributes of the activity of using a certain product rather than attributes of the product itself according to ISO 9241-11 \cite{iso19989241}. However, unlike simple signs which their users interpret out of intuition and experience, ontological terms require users to learn their semantical and syntactical features in order to interpret, typically through learning the term organization and reading the documentation. Therefore, all the three dimensions of semiotics are relevant to ontology usability. In fact, the survey result shown in Table~\ref{tab:poll} even indicated that the semantical and syntactical aspects may be more important than the pragmatical aspect, since only 2 out of the 11 top selections fall in the pragmatics group.

ISO 9241-11 \cite{iso19989241} listed the following three aspects of usability, \emph{effectiveness} is about accuracy and completeness of the result of that activity, \emph{efficiency} is the resources expended during the process, such as time and effort of learning and creating solutions, and \emph{satisfaction} is the freedom from discomfort and the positive attitude towards the use of the product. As we tried to decide which semiotical aspect impact which usability aspect, we found that each semiotical aspect may impact every usability aspect. For example, missing or insufficiently illustrated ontological terms (semantical aspect) may cause the user unable to complete his or her tasks (effectiveness), to spend more time learning the conceptualization (efficiency), and/or to feel discomfortable (satisfaction). Inconsistent or counter-intuitive organization of the ontological elements (syntactical) may have the same effect in terms of effectiveness, efficiency and satisfaction, and the pragmatical aspect aligns well with the overall usability. Therefore, the semiotical aspects and the usability aspects are closely related, so it is reasonable to classify usability criteria with semiotical aspects.

The survey result brings feedbacks and inspirations to ontology developers. As indicated by the top selections in Table~\ref{tab:poll}, stating the purpose of the ontology explicitly, describing classes and relations in detail and providing abundant examples in the documentation will greatly help users understand and use the ontology. The purpose of an ontology is important probably because of the close relationship between usability and purpose. Usability is inherently associated with fitness, and fitness, as summed up by Terry Pratchett in his novel ``Moving Pictures'', means ``appropriateness to a purpose'' \cite{pratchett2005moving} (quoted by Brooke in \cite{brooke1996sus}). Besides the statements pool in Table~\ref{tab:statements-pool}, in the online survey we also invited participants to write down any additional statements from their point of view. One suggestion is about the provenance of components in an ontology, such as the cited source in the definition of a class or property, and the person who asserts the definition, etc. Another issue is about the serialization language of ontologies. It was mentioned that if an ontology is not serialized in a simple format such as Turtle, it can be difficult for a user to read and understand. Another participant proposed the issue of ontology maintenance/sustainability, such as the stability of the ontology over time and the level of maintenance support that the ontology has. In \cite{ma2013recent} Ma et al. discussed that to achieve better ontology applications, people need to balance the expressivity, implementability and maintainability of the ontology. The maintainability or sustainability is relevant to the usability of an ontology in a long term period.

In the online survey we also received active feedbacks about the organization and form of the statements. In the survey preparation we tried to group the statements into three categories following a semiotic framework, while in the survey we did not show the groups and listed the statements in a random order. Our intention is to avoid any bias that may be caused by those pre-defined groups. It was interesting to see that several participants suggested the statement pool should be categorized, especially from the point of view of an ontologist. Another participant suggested that there can be a separation of statements for subject matter experts and end users.

Survey participants also commented on the positive and negative forms of the statements. From the comments we could see that it is okay to use both forms in a questionnaire, but we should avoid duplicated statements, such as ``I thought the ontology was easy to use'' and ``I found the ontology very cumbersome to use.'' Considering those feedbacks, we organized two sets of statements for ontology usability evaluation in Table~\ref{tab:ous-draft} and Table~\ref{tab:ous}, one with only statements in positive form and the other with both positive and negative forms.
Besides the top 11 mostly voted statements in Table~\ref{tab:poll}, we also took a review of the least voted statements in the online poll (Table~\ref{tab:least}). Most of them have either an extreme or vague meaning. Statement 1 in Table~\ref{tab:least} is adapted from its negative form ``I needed to learn a lot of things before I could get going with this ontology''; statement 2 was originally ``The on-tology has unnecessary concepts''; statement 3 overlaps a lot in meaning with ``I found the concepts/relations in this ontology properly described in natural language'' but is less clear; statement 4 is very similar to ``I would imagine that most domain experts would understand this ontology very quickly'', and statement 5 similar to ``I found the various concepts in this ontology well integrated'' (which was selected 4 times).
\begin{table}
	\centering
\caption{The least voted statements in the online poll}
\label{tab:least}
\begin{tabular}{|p{0.09\textwidth}|p{0.6\textwidth}|p{0.13\textwidth}|p{0.06\textwidth}|}
	\hline Number & Statement & Category & Votes \\ 
	\hline 1 & I do not need to learn any extra things before I could get going with this ontology. & Pragmatics & 0 \\ 
	\hline 2 & The ontology does not have unnecessary concepts. & Syntax & 2 \\ 
	\hline 3 & The annotations are helpful. & Semantics & 2 \\ 
	\hline 4 & I would imagine that most people would learn to use this ontology very quickly. & Pragmatics & 2 \\ 
	\hline 5 & I found the various parts of this ontology were well integrated. & Syntax & 2 \\ 
	\hline 
\end{tabular} 
\end{table}

We also collected information about what ontologies the surveyees had worked with, the top ones are shown in Table~\ref{tab:ontologies}.
\begin{table}
	\centering
\caption{Ontologies that the online surveyees worked with}
\label{tab:ontologies}
\begin{tabular}{|l|l|}
	\hline Ontology & Number of people worked with it \\ 
	\hline SWEET & 11 \\ 
	\hline Dublin Core & 8 \\ 
	\hline FOAF & 7 \\ 
	\hline SKOS & 5 \\ 
	\hline PROV-O & 3 \\ 
	\hline GCIS & 3 \\ 
	\hline 
\end{tabular} 
\end{table}
We found that users of domain ontologies such as SWEET have different preferences on statements from users of general ontologies such as Dublin Core. Top 12 selections for SWEET users listed in Table~\ref{tab:sweet} are very similar with those in Table~\ref{tab:poll}, with only a few minor differences. For example, statement 6 in Table~\ref{tab:poll} (``I would imagine that most domain experts would understand this ontology very quickly'') is missing in Table~\ref{tab:sweet}, but it ranks 13th among SWEET users; statement 10 and 12 in Table~\ref{tab:sweet} is missing in Table 2, but they rank 12th and 13th among all the statements so did not make it to the top 11 in Table~\ref{tab:poll}.
\begin{table}
	\centering
\caption{Top 12 statements selected by SWEET users}
\label{tab:sweet}
\begin{tabular}{|l|p{0.7\textwidth}|l|}
	\hline Number & Statement & Votes \\ 
	\hline 1 & The purpose of this ontology is clear. & 8 \\ 
	\hline 2 & I think the documentation provides sufficient examples for me to make sure how to use the ontology. & 8 \\ 
	\hline 3 & I think the relations in this ontology relate appropriate concepts. & 7 \\ 
	\hline 4 & I found the concepts in this ontology properly described in natural language. & 6 \\ 
	\hline 5 & I am confident I understand the conceptualization of the ontology. & 6 \\ 
	\hline 6 & I think the attributes in this ontology describe the concepts well. & 5 \\ 
	\hline 7 & I found the subclasses in this ontology are properly defined. & 5 \\ 
	\hline 8 & I do not need the support of a person experienced with this ontology to be able to use it. & 5 \\ 
	\hline 9 & I found the relations in this ontology properly described in natural language. & 4 \\ 
	\hline 10 & I found the ontology brief but comprehensive. & 4 \\ 
	\hline 11 & I found the formal specification of concepts in this ontology coincides with their descriptions in natural language. & 4 \\ 
	\hline 12 & I find the ontology easy to understand. & 4 \\ 
	\hline 
\end{tabular} 
\end{table}
But among the top three selections by Dublin Core users shown in Table~\ref{tab:dc}, two of them (``I think that I would like to use this ontology frequently'' and ``It is clear to me how to use this ontology'') are missing in Table~\ref{tab:poll}, so for ontologies designed to be used across different domains, statements 2 and 3 in Table~\ref{tab:dc} could be added to the usability scale.
\begin{table}
	\centering
	\caption{Top 3 statements selected by Dublin Core users}
	\label{tab:dc}
	\begin{tabular}{|l|p{0.7\textwidth}|l|}
		\hline Number & Statement & Votes \\ 
		\hline 1 & I think the documentation provides sufficient examples for me to make sure how to use the ontology. & 7 \\ 
		\hline 2 & I think that I would like to use this ontology frequently. & 5 \\ 
		\hline 3 & It is clear to me how to use this ontology. & 4 \\ 
		\hline 
	\end{tabular} 
\end{table}
There are several issues that can be explored in future works. The first work is to have more case studies using the statements in Table~\ref{tab:ous-draft} and Table~\ref{tab:ous}. In this study we only carried out case studies of the ontology usability scale in the GCIS and the DCO projects. Although the feedbacks are positive, we want to hear more feedbacks and suggestions on the statements themselves, including both their forms and the orders, as well the topics covered. The second potential work is relevant to the ontology types. As Table~\ref{tab:ontologies} shows, among the ontologies that the survey participants had worked with, there are both upper ontologies (e.g. Dublin Core, PROV-O) and domain ontologies (e.g. SWEET, GCIS). The former are applicable across a range of domain and the latter are only used for a specific application or domain. Therefore, we may organize corresponding statements for the usability evaluation of those two types of ontologies, and we can take further surveys to see if there are any differences between the community's concerns on the two ontology types. In the current survey we did not ask the participants to specify their roles and experiences in the ontology work. The third potential work is that, if we are going to have new surveys, we can ask people about their roles (e.g. ontology developer, database curator, application developer, and so on.) and their experience with ontology use (e.g. number of years). Last, the fourth potential work is to enrich, update and reorganize the statement pool from the point of view on expressivity, implementability and maintainability of ontologies. This framework is slightly different from the semiotic framework on syntax, semantics and pragmatics and covers new aspects of ontology usability.

\section{Automatic provenance capturing framework}
\label{sec:framework}
In computer science, a framework is a parameterized system. Certain components of the framework could be customized to fulfill specific tasks. The specified provenance capturing framework in this thesis consists of the following components:
\begin{itemize}
	\item A \emph{platform} is the managing system that coordinates its front end, operators and store. 
	\item The \emph{front end} of the platform is the interface for the users to interact with the platform. It provides the users ways to input requests to the platform that could be fulfilled with certain operators. Usually a platform kernel, which is a special operator, interprets user actions into requests and forwards these requests to the platform. The front end also takes feedback from the operators of the platform after they finish processing requests and interprets it into user-friendly feedback to display to the users. A front end could be as simple as a line processor that deals with one line of input text in each round of interaction with the user, but it could also be as capable as a system monitor that receives every single event happened on the user interface of the operating system. For such capable front end, users could interact with it in ways far beyond inputting commands and looking at textual feedback. For example, a user could open a browser and download a file, in which case the front end will take the sequence of events and interpret it into something the platform kernel understands, such as a ``download file'' command.
	\item The \emph{operators} of the platform are provenance aware software tools or scripts that execute operations on data and record provenance at each execution time. They can be included in the platform as pre-installed utilities but users are expected to obtain new operators for new tasks from time to time. The front end and the platform kernel (if there exists one) does not necessarily know the operational logics of a certain operator but must know how to invoke the operator according to the requests from the users and how to receive feedback from the operator.
	\item The \emph{kernel} of the platform is an optional special operator that directly interact with the front end. It deals with all the requests interpreted by the front end either itself or through dispatching to other operators. If there is a kernel in the platform, it must be the only operator that directly interact with the front end, and all the other operators must only interact with the kernel operator. In this thesis we focus on the case where there is a kernel. One important job of the kernel is to assign consistent URIs to the data objects across different operations. We will go to the details of this point in Section~\ref{sec:transition}.
	\item The \emph{store} of the platform takes charge of temporarily holding in-memory provenance fragments and storing provenance on disks. For a platform compliant with PROV-PUB-O, its store is equivalent with an RDF graph in the vocabulary of PROV-PUB-O.
\end{itemize}
The front end will invoke operators when the user launches a command through the front end. Operations on data are then delegated to various operators and execution results are sent back to the front end to enable it to provide meaningful feedback to the user. Execution of operations may require accesses to the store to operate in-memory or on-disk data objects. These processes are illustrated in Figure~\ref{fig:invoke} and Figure~\ref{fig:execute}.
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{invoke.png}
	\caption{Front end invoke operators to finish tasks}
	\label{fig:invoke}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{execute.png}
	\caption{Operators access store and notify front end}
	\label{fig:execute}
\end{figure}
An important feature of the platform is that the front end and the store both only interact with operators, as shown in Figure~\ref{fig:platform}.
\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{platform.png}
	\caption{Front end and store both only interact with operators}
	\label{fig:platform}
\end{figure}
A corollary of this feature, is that the creation and retrieving of provenance should be on those operators, rather than the front end or the store. Because if the operators do not create provenance, the store has no way to get provenance since it only interacts with operators. Provenance would then get lost because it has to be saved in the store. Operators must be able to retrieve provenance for the readers of the research publications to reproduce the published results because only they have access to the store, where provenance is kept.

Since neither the front end nor the platform kernel necessarily know the operational logic of every possible operator they are to invoke for some task, it is impossible to implement the provenance capturing function as part of the front end or platform kernel. For example, an operator may use several data objects to generate multiple other data objects. Some of these objects may be passed as parameters of function calls, others may be defined as the return values, and positions of these objects (whether they are parameters or return values) could be arbitrarily decided by the developer of the operator (software or scripts), so the job of creating and retrieving provenance has to be done by the operators. In the case where a kernel exists, it has the job of connecting provenance fragments generated within other operators. For example, an operator O1 used data D1 as one of its arguments and generated data D2 as its return value. In this case the operator O1 knows what D1 and D2 are but does not know the identities of D1 and D2 within the context where O1 gets invoked. In other words, O1 knows D1 is the $n$-th argument, and D2 the return value, but O1 has no way to know which variable is holding its $n$-th argument and which variable will hold its return value. The kernel operator knows where each argument comes from and where each return value goes to, so it has to be involved in provenance capturing to assign consistent URIs to data objects and results.

Provenance collecting frameworks proposed before the publication of PROV-O such as \cite{simmhan2006framework} must depend on a central provenance service to collect provenance graph fragments provided by the various components operating on data to ensure these fragments are consistent with each other and can be put together to form the whole provenance graph. With PROV-PUB-O/P, which is a specialization of PROV-O, such a centralized provenance authority just need to simply concatenate the lists of triples generated by the operators, as long as all the operators format their provenance pieces with the same terminology. This assumption holds given that there is a terminology to be used that has been publicly published and widely adopted.

The two functions of the platform, namely the creation of provenance and the replication of the research work with the saved provenance, do not have big differences between them. The only difference is that the replication requires an additional ``load provenance'' operation at the very beginning.

\subsection{System state transition rules}
\label{sec:transition}
Given a front end, a finite set of operators including the kernel, and a store, the platform becomes a system. The state of the system gets changed only when one of the following events happens:
\begin{itemize}
	\item The system gets started.
	\item One operation gets executed by a certain operator.
	\item The system is closed.
\end{itemize}
Of these three events, the first and the third does not require special attention in terms of provenance capturing. At the start-up time of the system, the store just needs to be initialized to an empty graph, and at the ending time of the system, the store needs to be saved to disk.

\subsubsection{What operation means}
Before we focus on the second event, we want to make clear what does ``an operation'' mean. In this thesis, an operation must have the following abstract form:
\begin{equation}
\label{eq:fun}
\textrm{function}(\textrm{argument1}, \textrm{argument2}, \dots, \textrm{argumentN})\rightarrow \textrm{return}
\end{equation}
The meaning of this operation is that a function of an operator with N arguments is invoked to generate a return. Note that through simple wrapping, logical and arithmetic operations can be converted to this form. For example, x plus y gets z could be written as a function ``plus'' taking two arguments x and y, and generating z:
\begin{equation}
\textrm{plus}(x, y)\rightarrow z
\end{equation}
We do not allow the function to change some of its arguments as a side effect, this demand can be fulfilled by rewriting the function definition to move these arguments to the return side, in which case the return will have these changed arguments all held in some data structure such as a list or a dictionary.

Here we follow the kernel language approach described in Chapter 2.3 of the book written by Peter Van Roy and Seif Haridi~\cite{van2004concepts}. Table 2.1 in this chapter summarizes all the basic operations needed by a general programming language, thus these operations must be sufficient for creating results in research publications.

In fact, the kernel language defined in Table 2.1 in \cite{van2004concepts} could be redefined as in Table~\ref{tab:kernel}. 
\begin{table}
	\centering
	\begin{tabular}{|rrll|}
		\hline $<s>$ & ::= & skip & Empty statement \\ 
		  & | & $<s>_1$ $<s>_2$ & Statement sequence \\ 
		  & | & $<x>_2\rightarrow <x>_1$ & Variable binding \\ 
		  & | & $<v>\rightarrow<x>$ & Value assignment \\ 
		  & | & $f(<a>_1\dots<a>_n)\rightarrow r$ & Operation invocation \\ 
		\hline 
	\end{tabular} 
	\caption{Kernel language adapted from Van Roy and Haridi's work}
	\label{tab:kernel}
\end{table}
The differences are:
\begin{itemize}
	\item Variable creation and binding are in one step (this is the case for functional programming languages, and is adopted by Python and R), so there is no separate variable creation step.
	\item Procedure applications are replaced by operation invocations. To convert a procedure application to an operation invocation, we just need to move those arguments to be changed to the return value side (the $r$ side).
	\item Conditional and pattern matching statements are removed, they must be written in the form of operation invocations.
\end{itemize}
In fact, variable binding and value assignment could also be written in the form of operation invocations. Thus the program could be further simplified to just a sequence of operation invocations: variable binding could be rewritten as the kernel operation ``bind($<x>_2$)$\rightarrow <x>_1$'', and value assignment could be written as ``assign($<v>$)$\rightarrow <x>$''. Therefore, $<x>_2\rightarrow <x>_1$ and $<v>\rightarrow<x>$ could be seen as the syntactical sugar provided by certain kernels. Certain kernels could allow conditional statements and pattern matching statements and many more conveniences implemented in this manner. That is, they are actually operation invocations to the kernel.

\subsubsection{Operation invocation rules}
To ensure that proper provenance gets captured as a sequence of operations in the form of Equation~\ref{eq:fun} are invoked, the kernel and other operators need to effectively cooperate. Invocations of operations fall into the following two categories:
\begin{itemize}
	\item The operation is carried out directly by the kernel, or
	\item The operation is carried out by another operator invoked by the kernel.
\end{itemize}
Below we elaborate what the kernel and the working operator will do for these two categories of operation invocations.

\noindent\textbf{Kernel carries out the operation:}

For the situation that an operation gets executed directly by the kernel, the kernel will generate a fresh URI for the operation, and the operation will be asserted to be an instance of a certain class in PROV-PUB-O according to the kernel's knowledge about the operation (for example, the kernel may assert the operation to be a pub:Obtaining, or a pub:Loading, and so on). The data objects used in the operation's arguments will be recorded with proper sub-properties of prov:used, that is, pub:obtained, pub:loaded, and so on. These data objects will get fresh URIs generated by the kernel. Finally, the fact of the operation generating the returned data object will also be recorded as a triple in the store.

For example, suppose the read\_csv(input\_file)-->csv\_content operation is handled directly by the kernel, then the following triples will be added to the store once this operation gets executed:
\begin{itemize}
	\item (:read\_csv, rdf:type, pub:Loading)
	\item (:read\_csv, pub:loaded, :input\_file)
	\item (:read\_csv, prov:generated, :csv\_content)
	\item (:read\_csv, dct:description, ``Read data in CSV format from the input\_file to the csv\_content object.'')
\end{itemize}
The pub:language and pub:code properties of :read\_csv can also be provided according to specific kernel configurations.

Note that URIs such as :read\_csv, :input\_file and :csv\_content could be replaced with any fresh URIs not yet been used by other data objects.

These provenance capturing actions are taken in addition to the normal actions performed by the platform.

\noindent\textbf{Another operator carries out the operation:}

A kernel usually provides only the most basic operations such as value assignment, variable binding, logic and arithmetic operations, and conditional execution. More complicated computations are typically carried out by some provenance aware operator other than the kernel. In this case, the kernel knows the variable carrying the return value of the operation and all the arguments that could potentially be used by the operation, but it does not know the detailed usage of these arguments, neither does the kernel know the specific type of the operation. The operator needs to fill in the blanks where the kernel does not know about it.

For example, suppose the read\_csv(input\_file)$\rightarrow$csv\_content operation is handled by a provenance aware operator instead of the kernel, the same list of triples need to be generated:
\begin{itemize}
	\item (:read\_csv, rdf:type, pub:Loading)
	\item (:read\_csv, pub:loaded, :input\_file)
	\item (:read\_csv, prov:generated, :csv\_content)
	\item (:read\_csv, dct:description, ``Read data in CSV format from the input\_file to the csv\_content object.'')
\end{itemize}
All the fresh URIs for read\_csv, input\_file and csv\_content must be provided by the kernel, the kernel will pass the dictionary of variable-URI mappings to the operator. The operator knows the relationships among these data objects, so it is responsible to generate all the triples with the URIs provided by the kernel. It can also generate more triples that describe useful information such as the programming language and the library dependency.

Note that when generating the URI for read\_csv, the URI is not for the function, but for the particular invocation of the function read\_csv, so later invocations of the same function will need different fresh URIs to differentiate among the different function invocations. The same rule holds for different references of the same data object generated at different occasions. Since the internal value changed, they are considered different data objects and need different URIs. Data objects on the left hand side of the operations (arguments of the operations) are considered ``read only'', so they should reuse their existing URIs if such URIs have been created for them.

Since prov:generated is an inverse property of prov:wasGeneratedBy, the triple (:csv\_content, prov:wasGeneratedBy, :read\_csv) could either be added to the provenance graph also by the operator, or deduced later by an OWL reasoner. This \emph{was generated by} triple makes the trace of a data object or result ``one way'': a data object/result was generated by an activity, which in turn used another data object, which in turn was generated by another activity, and so on.

\subsection{A comprehensive example}
\label{sec:example}
Suppose we have the following list of operations:
\begin{enumerate}
	\item obtain\_data()$\rightarrow$input\_file
	\item read\_csv(input\_file)$\rightarrow$csv\_content
	\item transform\_data(csv\_content)$\rightarrow$plot\_ready\_data
	\item save\_data(plot\_ready\_data)$\rightarrow$data\_file
	\item plot\_data(plot\_ready\_data)$\rightarrow$figure
\end{enumerate}
and they are all carried out by non-kernel operators. Below is a step-by-step illustration of how each operation should change the store. It shows the minimum set of triples that every implementation of the framework needs to generate.

Step 1: obtain\_data()$\rightarrow$input\_file. The kernel is responsible for parsing the operation, and generating fresh URIs :obtain\_data and :input\_file for the invocation of the obtain\_data() operation and the generated data object input\_file, respectively. The operator providing the obtain\_data function is responsible for generating the following triples based on the URIs given by the kernel to add to the store:
\begin{itemize}
	\item (:obtain\_data, rdf:type, pub:Obtaining)
	\item (:obtain\_data, prov:generated, :input\_file)
\end{itemize}
The triple (:input\_file, prov:wasGeneratedBy, :obtain\_data) would also be implicitly or explicitly in the provenance graph, for reasons mentioned in the previous section.
Optionally the operator may also generate the following triple to explain the obtaining process:
\begin{itemize}
	\item (:obtain\_data, dct:description, "Filled out the data request form at \url{http://www7.ncdc.noaa.gov/CDO/CDODivisionalSelect.jsp#} with period: 1970.1--2010.12, and downloaded the requested data.")
\end{itemize}
and the following triple to describe the obtained data:
\begin{itemize}
	\item (:input\_file, rdf:type, pub:OnDiskData)
	\item (:input\_file, pub:format, "CSV")
	\item (:input\_file, dct:description, "Data in the CDODiv2177686828992.txt file.")
\end{itemize}
The operator may also describe the dataset it obtained data from, with some other ontology focusing on dataset description.

Step 2: read\_csv(input\_file)$\rightarrow$csv\_content. The kernel is responsible for parsing the operation, and generating fresh URIs :read\_csv and :csv\_content for the operation and the generated data object, respectively. The URI for input\_file should be reused because it has not changed from when generated until it is passed as an argument of this operation. The provider of the read\_csv operation is responsible for generating the following triples:
\begin{itemize}
	\item (:read\_csv, rdf:type, pub:Loading)
	\item (:read\_csv, pub:loaded, :input\_file)
	\item (:read\_csv, prov:generated, :csv\_content)
\end{itemize}
Optionally, the operator may also generate some explanation text for the data loading activity:
\begin{itemize}
	\item (:read\_csv, dct:description, "Read CSV data in file CDODiv2177686828992.txt to variable csv\_content")
\end{itemize}
The file name is known by the operator since it is included in the input\_file argument. The variable name needs to be passed by the kernel to the operator. As will be shown in Section~\ref{sec:prototype}, at least in Python, there is a way to pass such ``hidden arguments'' in the background without bothering the user with mysterious additional arguments.

The operator providing the read\_csv function may also provide additional description triples for the :input\_file data object from a different perspective from the data obtaining operator. In this case there is no such additional description to add.

Finally, the operator may provide description for the :csv\_content data object:
\begin{itemize}
	\item (:csv\_content, rdf:type, pub:InMemoryData)
	\item (:csv\_content, dct:description, "Data held by variable csv\_content.")
\end{itemize}

Step 3: transform\_data(csv\_content)$\rightarrow$plot\_ready\_data. The kernel should prepare fresh URIs for the transform\_data operation and the plot\_ready\_data object (let's say they are :transform\_data and :plot\_ready\_data), and reuse the existing URI for the csv\_content object (that is, :csv\_content). The operator should generate the following triples:
\begin{itemize}
	\item (:transform\_data, rdf:type, pub:Transformation)
	\item (:transform\_data, pub:transformed, :csv\_content)
	\item (:transform\_data, prov:generated, :plot\_ready\_data)
\end{itemize}
and it may optionally generate description of the operation:
\begin{itemize}
	\item (:transform\_data, dct:description, "Sum up values on columns CDD and HDD for each year, convert these sums into percentages relative to the average of the first 31 years, delete the remaining columns.")
\end{itemize}
In this example, the transform\_data operation is very problem specific and not useful to other use cases. In the real life, as will be shown in Section~\ref{sec:prototype}, such data transformation is usually decomposed into several general operations such as selecting certain columns (also called subsetting, slicing, and so on), calculating the average for a certain list of values, arithmetic calculation for each value in a list, and so on. Here we put these transformations together as one to avoid listing too many examples of the same kind of data generation operation and to make one complete example of the whole data processing workflow.

The operator providing the transform\_data function may provide additional description of the csv\_content data object according to its knowledge about it. We omit it here. Finally, the operator may generate some triples to describe the data object it generated:
\begin{itemize}
	\item (:plot\_ready\_data, rdf:type, pub:InMemoryData)
	\item (:plot\_ready\_data, dct:description, "Data held by variable :plot\_ready\_data.")
\end{itemize}

Step 4: save\_data(plot\_ready\_data)$\rightarrow$data\_file. Same URI generation jobs are to be done by the kernel. :save\_data for the operation and :data\_file for the generated data object should be ready after kernel does its job. :plot\_ready\_data should get reused. Based on these data object-URI mappings, the operator should generate the following triples:
\begin{itemize}
	\item (:save\_data, rdf:type, pub:Saving)
	\item (:save\_data, pub:saved, :plot\_ready\_data)
	\item (:save\_data, prov:generated, :data\_file)
\end{itemize}
and may also describe the operation with the triple:
\begin{itemize}
	\item (:save\_data, dct:description, "Save data held by the plot\_ready\_data variable to the file data.csv")
\end{itemize}
The save\_data function usually takes as an argument to specify the format of the file to store the data. This information may also be inferred from the extension of the file name given to the function.

Finally, the operator may describe the generated data file by triples such as:
\begin{itemize}
	\item (:data\_file, rdf:type, pub:OnDiskData)
	\item (:data\_file, pub:format, "CSV")
	\item (:data\_file, dct:description, "Data in the file data.csv")
\end{itemize}

Step 5: plot\_data(plot\_ready\_data)$\rightarrow$figure. The kernel should generate the fresh URI :plot\_data for the operation and :figure for the generated result. The variable plot\_ready\_data has not changed since its creation, so the URI :plot\_ready\_data can still be reused here. The operator is responsible for generating the following triples:
\begin{itemize}
	\item (:plot\_data, rdf:type, pub:Visualization)
	\item (:plot\_data, pub:visualized, :plot\_ready\_data)
	\item (:plot\_data, prov:generated, :figure)
\end{itemize}
optionally plus the description of the operation:
\begin{itemize}
	\item (:plot\_data, dct:description, "Plotted data in variable plot\_ready\_data to generate figure.")
\end{itemize}
The description could get enriched by additional information provided by the arguments, such as the type of the plot and the size of the generated figure.

Finally, description for the figure usually should be generated:
\begin{itemize}
	\item (:figure, rdf:type, pub:Figure)
	\item (:figure, pub:format, "PNG")
	\item (:figure, dct:description, "Figure plotted with arguments kind=bar, figsize=(20,10).")
\end{itemize}
If this figure gets adopted in the final publication, the author could assert that the figure in the publication is equivalent to :figure here with the owl:sameAs predicate. That is the reason why we assert the figure as an instance of pub:Figure (which is a subclass of pub:PublishedResult) although it may get discarded and end up not published.

After the five operations get executed by the framework, the framework will have the full trace of the result figure :figure as follows, among other related information:
\begin{itemize}
	\item (:obtain\_data, prov:generated, :input\_file)
	\item (:read\_csv, pub:loaded, :input\_file)
	\item (:read\_csv, prov:generated, :csv\_content)
	\item (:transform\_data, pub:transformed, :csv\_content)
	\item (:transform\_data, prov:generated, :plot\_ready\_data)
	\item (:plot\_data, pub:visualized, :plot\_ready\_data)
	\item (:plot\_data, prov:generated, :figure)
\end{itemize}

\subsection{Effectiveness evaluation}
To evaluate the effectivenss of the framework specified above, we looked at the provenance records of all the tables and figures in Chapter 4 of National Climate Assessment Report 2014 to see if the operations mentioned in the generation process descriptions are all covered by the framework. That is, whether all the result generation processes could be represented as a sequence of operations in the form of Equation~\ref{eq:fun}. We did not find any operation not representable in this form. The details of the investigation can be found in Chapter~\ref{ch:case-study}.

\subsection{Non-functional requirements}
The previous two sections specified and illustrated the functions a provenance-aware platform should implement. In addition to them, the platform compliant with the framework also needs to meet some non-functional requirements as much as possible to ensure its usability.

First, it is desirable to support multiple forms of input. For example, to support multiple programming languages. That is, users should be likely to find one of their favorite ways of doing certain things acceptable by the front end. One example is one of their favorite programming languages is acceptable by the front end of the platform. In this case the users do not have to learn a new programming language in order to use the platform. In the ideal case, the platform includes provenance aware versions of all the software tools the users use to create research publications. For example, the platform includes provenance aware Web browsers and table creation tools, and the user could launch one of each kind within the platform so that the browsing and table creating actions are monitored by the kernel and get recorded automatically in a similar way as illustrated in the last section. The complication could be that the operator needs to provide the kernel with the operations in the form of Equation~\ref{eq:fun}, then the kernel could generate fresh URIs and the operator could generate provenance triples based on these URIs.

Second, it is desirable to hide as much provenance details as possible from the user of the platform. However, when requested, the provenance details should be accessible to the user for review and modification. For example, the provenance aware functions should not expose provenance related arguments to the user or even ask the user to provide proper values for these arguments. Users would be annoyed and/or confused if they have to pass four extra parameters each time they call a provenance-aware version of their familiar function. Invocation of a provenance aware function should look as much as possible just like the invocation of a normal function. On the other hand, for provenance experts who want to see and have more control over the provenance get recorded, the platform should provide a way to show what is happening under the hood and what is in the provenance store so far.

In the next section, we will describe a prototype that is compliant with the framework specification and implemented with these non-functional requirements in mind.
% recap the three requirements

% front end supporting multiple programming languages and extensible

% capturing mechanism that does not require user involvement

\section{A proof-of-concept prototype}
\label{sec:prototype}
Based on the framework specification described in the last section, we implemented a prototype which has Jupyter Notebook\footnote{The Jupyter Notebook is part of the Jupyter project: \url{http://jupyter.org/}, accessed on November 28th, 2015.} as its front end, IPython as its kernel operator, several Python modules wrapping the functions of pandas, numpy and matplotlib.pyplot Python libraries as its data processing operators, and a Graph object of the rdflib library as its provenance store. The Python programming language is used to showcase the concept here, but Jupyter Notebook is language agnostic and kernels and operators could be implemented for other languages in the same manner.

The prototype supports the following forms of operations:
\begin{enumerate}
	\item Function invocation: $r = f(a_1\dots a_n)$
	\item Procedure invocation: $p(a_1\dots a_n)$
	\item Assignment: $l = r$
	\item Deletion: del $o$[$k$]
	\item Normal Python scripts
\end{enumerate}
These operation forms are picked from the Python code used to reproduce a figure in the case study described in Chapter~\ref{ch:case-study}. The intention is to make the operation invocations look exactly the same as normal Python scripts, and at the same time, cover as many frequently used Python code patterns as possible.

The first form, function invocation, intuitively corresponds to the abstract operation pattern in Equation~\ref{eq:fun}. The important difference of the first form from a normal Python script is that the arguments $<a>_1\dots<a>_n$ are all read-only. It does not limit the capability of the function because if one argument, say $a_1$, is to get changed by the function $f$, then the function definition could change so that it returns a tuple $(r, a_1)$ to avoid the necessity of changing one of function $f$'s arguments.

The second form, procedure invocation, is necessary because there are certain functions in Python that do not return data objects. They generate data objects, but these objects could not be held by in-memory variables. For example, consider the save\_data function mentioned in Section~\ref{sec:example}: when implemented with a Python function, it normally takes as one of its arguments the name of the file to save the data. It could be defined to return a file object to fit the first form, but that would be against the common Python code patterns and make the invocation in an awkward form. That is the reason we introduce the second form. It corresponds to the following abstract operation form:
\begin{equation}
p(a_2\dots a_n)\rightarrow \textrm{file}(a_1)
\end{equation}
where $\textrm{file}(a_1)$ is the on-disk data object with file name $a_1$.

The third form, assignment, covers data and result generation operations achieved through Python operators. Examples are arithmetic operations such as ``$+$'', ``$-$'', ``$\times$'' and ``$\div$'', logical operators such as ``and'' and ``or'', and member access operators such as ``.'' and ``[]''. $r$ in the third form is usually an expression containing these Python operators, and this form is first reduced to $l = \textrm{assign}(r)$ (in the first form) where assign is a built-in function implemented within the kernel implemented in an IPython cell magic function called ``prov''.

The fourth form, deletion, specifically covers the operations achieved through the Python del operator. One example is to use this operator to drop a column in a data frame. When reading an operation in this form, the kernel rewrites it to $o = \textrm{delete}(o, k)$ (in the first form) and execute, where delete is a built-in function implemented within the kernel implemented in the same ``prov'' IPython cell magic.

Operations written in the first four forms are all provenance aware, but there are some Python scripts that do not have meaningful provenance to capture. Examples are inspection of data objects and manipulating the provenance store content. The fifth form is for such provenance-unaware operations. Users could decide whether to capture provenance or not with the ``prov'' IPython cell magic that is responsible for rewriting scripts in the third and fourth forms.

The ``prov'' cell magic maintains the URIs and texts of variables and expressions with several Python dictionaries, and these dictionaries, along with other provenance related variables, are initialized with the ``initprov'' cell magic. To tell the platform to start tracking provenance, the user just need to call the ``initprov'' cell magic once, and to record provenance captured by the provenance aware function and procedure invocations in a cell, the user just need to call the ``prov'' cell magic in the cell.

The following provenance aware functions are implemented to show how to define provenance aware functions for the platform and use the platform:
\begin{itemize}
	\item assign(rhs, **kwargs) in the \emph{operators} module
	\item delete(obj, key, **kwargs) in the \emph{operators} module
	\item read\_csv(csvinput, delimiter=',', skipinitialspace=True, **kwargs) in the \emph{dataloader} module
	\item group\_aggregate(dataframe, keys, aggregation, **kwargs) in the \emph{datatransformer} module
	\item average(li, **kwargs) in the \emph{datatransformer} module
	\item write\_csv(dataframe, csvoutput, delimiter=',', index=True, **kwargs) in the \emph{datasaver} module
	\item plot(dataframe, kind, figsize, **kwargs) in the \emph{dataplotter} module
\end{itemize}
The \emph{**kwargs} (key word arguments) in the argument lists are for provenance related arguments to be added by the kernel before these functions get actually executed. For example, in a provenance aware cell (indicated with the call of the ``prov'' cell magic), if the user writes the following line of code:
\begin{quotation}
\noindent\texttt{csv\_content = read\_csv('CDODiv2177686828992.txt', delimiter=' ')}
\end{quotation}
The actual code gets executed is:
\begin{quotation}
	\noindent...
	
	\noindent\texttt{csv\_content = read\_csv('CDODiv2177686828992.txt', delimiter=' ', namespace=\_\_NAMESPACE\_\_, textdict=\_\_TEXTDICT\_\_, uridict=\_\_URIDICT\_\_, provgraph=\_\_PROV\_\_)}
	
	\noindent...
\end{quotation}
where \_\_NAMESPACE\_\_, \_\_TEXTDICT\_\_, \_\_URIDICT\_\_ and \_\_PROV\_\_ are variables created by the ``initprov'' cell magic and maintained by the ``prov'' cell magic and the provenance aware functions. The point here is that the users do not need to know the existence of these variables, so it is the kernel's job to add in the provenance related arguments.

For expert users who would like to review the provenance captured so far and/or manipulate the provenance graph, they could do these by read and/or write the \emph{\_\_PROV\_\_} variable.

\subsection{A concrete example}
In this section, we walk through the whole process of the creation of a figure. The source code for this example is available in Appendix~\ref{ap:prototype}. 

The figure was generated based on a downloaded CSV file with the following IPython scripts:
\begin{enumerate}
	\item\noindent import sys
	
	\noindent sys.path.append('prov')
	
	\noindent import dataloader as dl
	
	\noindent import datatransformer as dt
	
	\noindent import datasaver as ds
	
	\noindent import dataplotter as dp
	
	\noindent import provmagic
	
	\noindent import numpy as np
	\item \%\%initprov
	\item csv\_content = dl.read\_csv('CDODiv2177686828992.txt', delimiter=' ')
	\item dd = csv\_content[['YearMonth','HDD','CDD']]
	\item dd.loc[:,'Year'] = dd['YearMonth']//100
	\item del dd['YearMonth']
	\item dd\_year = dt.group\_aggregate(dd, 'Year', np.sum)
	\item cdd\_avg = dt.average(dd\_year['CDD'][0:31])
	\item hdd\_avg = dt.average(dd\_year['HDD'][0:31])
	\item dd\_year.loc[:, 'HDD'] = dd\_year['HDD']/hdd\_avg*100-100
	\item dd\_year.loc[:, 'CDD'] = dd\_year['CDD']/cdd\_avg*100-100
	\item ds.write\_csv(dd\_year, 'dd\_year.csv')
	\item fig = dp.plot(dd\_year, kind='bar', figsize=(20,10))
\end{enumerate}
The downloaded CSV file, CDODiv2177686828992.txt, had the following content:
\begin{quotation}\tt
	\noindent ... YearMonth ... CDD \ \ \ \ HDD ...
	 
	\noindent ... \ \ \ 197001 ... \ \ 2 \ \ \ 1067 ...
	 
	\noindent ... \ \ \ 197002 ... \ \ 3 \ \ \ \ 763 ...
	
	\noindent ... 
\end{quotation}
The columns not of interest in this use case are omitted. The first block of scripts makes the cell magic functions and the provenance aware functions accessible from the Jupyter notebook (that is, the rest of the code). It also imports the NumPy Python library to be used in the notebook.

The second script item is a call of the \emph{initprov} cell magic. When the IPython kernel reads this line, it will invoke the initprov(self, line, cell) function defined in the provmagic module. This function creates and initializes the provenance related global variables such as \_\_NAMESPACE\_\_, \_\_OBJDICT\_\_, \_\_TEXTDICT\_\_, \_\_URIDICT\_\_ and \_\_PROV\_\_. 

The \_\_NAMESPACE\_\_ variable is the namespace for the local instances such as operations, expressions and data objects. Users can set its value simply by assigning the namespace string to the \_\_NAMESPACE\_\_ variable:

\_\_NAMESPACE\_\_ = 'http://my.domain.org/'

If not given, the initprov cell magic will set its value to \url{http://example.org/}, which is the case for this example.

The \_\_OBJDICT\_\_ variable is a dictionary recording URIs for data objects involved in the Jupyter notebook. It is maintained by the IPython kernel with the \emph{prov} cell magic and used by provenance aware functions to ensure the consistency of URIs assigned to consecutive appearances of the same data object. If the object changed, a fresh URI will be assigned to it, otherwise the data object will reuse its existing URI to keep the RDF triples across different operations connected.

The \_\_TEXTDICT\_\_ variable is a dictionary recording textual representations of function names, arguments and variables. Entries of this dictionary will be filled in by the IPython kernel with the \emph{prov} cell magic before each provenance aware function gets invoked. The dictionary will be passed as an argument to the provenance aware function to help the function create meaningful descriptions of the data objects it used and generated. Examples will be available when we explain the following scripts.

The \_\_URIDICT\_\_ variable is a dictionary recording URIs of operations and data objects. It is also filled in by the IPython kernel with the \emph{prov} cell magic and used by provenance aware functions to generate correct RDF triples. Examples will be available in the explanation of the following scripts.

The \_\_PROV\_\_ variable is an RDF graph that represents the provenance store. All the generated provenance triples are added to this graph.

The cell magics defined in the provmagic module all have the argument ``-v'' or ``--verbose''. When set, it makes the cell magic print the actual code executed behind the scene. If we replace the second script item with:
\begin{quotation}
\noindent\%\%initprov -v
\end{quotation}
The output of the cell will include the following information when executed:
\begin{quotation}
\noindent Actual code executed:

\noindent from rdflib import Graph, Namespace, URIRef, Literal

\noindent from rdflib.namespace import DC, NamespaceManager

\noindent import operators

\noindent if '\_\_NAMESPACE\_\_' not in globals():

\noindent \_\_NAMESPACE\_\_ = 'http://example.org/'

\noindent \_\_OBJDICT\_\_ = \{\}

\noindent \_\_URIDICT\_\_ = \{\}

\noindent \_\_TEXTDICT\_\_ = \{\}

\noindent \_\_PROV\_\_ = Graph()

\noindent pub = Namespace("\url{http://orion.tw.rpi.edu/~fulinyun/ontology/prov-pub/}")

\noindent prov = Namespace("\url{http://www.w3.org/ns/prov#}")

\noindent example = Namespace(\_\_NAMESPACE\_\_)

\noindent namespace\_manager = NamespaceManager(Graph())

\noindent namespace\_manager.bind('pub', pub, override=False)

\noindent namespace\_manager.bind('prov', prov, override=False)

\noindent namespace\_manager.bind('dc', DC, override=False)

\noindent namespace\_manager.bind('', example, override=False)

\noindent \_\_PROV\_\_.namespace\_manager = namespace\_manager
\end{quotation}
which lets expert users know what exactly is going on and enables them to make changes.

The \emph{initprov} cell magic calls the \emph{prov} magic function to deal with provenance aware operations in the cell, so users do not need to call the \emph{prov} magic if they write the scripts in the same cell. To enable provenance aware processing for a new cell, the user needs to call the \emph{prov} magic with ``\%\%prov''. We assume that all the following scripts were all written in the same cell in this example, so it is not necessary to call the \emph{prov} cell magic.

When the kernel receives script item 3, it parses the line to recognize the provenance aware function all and rewrites the line to:
\begin{quotation}
	\noindent csv\_content = dl.read\_csv('CDODiv2177686828992.txt', delimiter=' ', namespace=\_\_NAMESPACE\_\_, textdict=\_\_TEXTDICT\_\_, uridict=\_\_URIDICT\_\_, provgraph=\_\_PROV\_\_)
\end{quotation}
before which, entries are filled in to the dictionaries:
\begin{quotation}
	\noindent \_\_TEXTDICT\_\_ = \{\}
	
	\noindent \_\_TEXTDICT\_\_[0] = "'CDODiv2177686828992.txt'"
	
	\noindent if "'CDODiv2177686828992.txt'" in \_\_OBJDICT\_\_:
	
	\noindent \ \ \_\_URIDICT\_\_[0] = \_\_OBJDICT\_\_["'CDODiv2177686828992.txt'"]
	
	\noindent else:
	
	\noindent \ \ \_\_OBJDICT\_\_["'CDODiv2177686828992.txt'"] = \_\_URIDICT\_\_[0] = \_\_NAMESPACE\_\_+'\%27CDODiv2177...txt\%27\_2015\_11\_17T15\_16\_30Z\_a'
	
	\noindent \_\_TEXTDICT\_\_['delimiter'] = "' '"
	
	\noindent if "' '" in \_\_OBJDICT\_\_:
	
	\noindent \ \ \_\_URIDICT\_\_['delimiter'] = \_\_OBJDICT\_\_["' '"]
	
	\noindent else:
	
	\noindent \ \ \_\_OBJDICT\_\_["' '"] = \_\_URIDICT\_\_['delimiter'] = \_\_NAMESPACE\_\_+'\%27+\%27\_2015\_11\_17T15\_16\_30Z\_a'
	
	\noindent \_\_TEXTDICT\_\_['fun'] = "dl.read\_csv"
	
	\noindent \_\_URIDICT\_\_['fun'] = \_\_NAMESPACE\_\_+'dl.read\_csv\_2015\_11\_17T15\_16\_30Z'
	
	\noindent \_\_TEXTDICT\_\_['return'] = "csv\_content"
	
	\noindent \_\_OBJDICT\_\_["csv\_content"] = \_\_URIDICT\_\_['return'] = \_\_NAMESPACE\_\_+'csv\_content\_2015\_11\_17T15\_16\_30Z'
\end{quotation}
and the following RDF triple about the code of the operation is added to \_\_PROV\_\_:
\begin{quotation}
	\noindent (:dl.read\_csv\_2015\_11\_17T15\_16\_30Z, pub:code, "csv\_content = dl.read\_csv('CDODiv2177686828992.txt', delimiter=' ')")
\end{quotation} 
Variable names and execution times are used to create fresh URIs. Special entries are created for operations and return values. Based on the information created by the cell magic function and passed to the provenance aware read\_csv function, the function can create the following RDF triples (in Turtle format):
\begin{quotation}
	\noindent:dl.read\_csv\_2015\_11\_17T15\_16\_30Z a pub:Loading ;
	
	\noindent \ \ pub:language "Python" ;
	
	\noindent \ \ pub:code "csv\_content = dl.read\_csv('CDODiv2177686828992.txt', delimiter=' ')" ;
	
	\noindent \ \ dc:description "Read CSV data in file CDODiv2177686828992.txt to variable csv\_content" ;
	
	\noindent \ \ prov:startedAtTime "2015-11-17T15:16:30+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent \ \ prov:endedAtTime "2015-11-17T15:16:30+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent \ \ pub:loaded <\url{http://example.org/%27CDODiv2177686828992.txt%27_2015_11_17T15_16_30Z_a}> ;
	
	\noindent \ \ prov:used :pandas .
	
	\noindent \ \ prov:generated :csv\_content\_2015\_11\_17T15\_16\_30Z ;
	
	\noindent<\url{http://example.org/%27CDODiv2177686828992.txt%27_2015_11_17T15_16_30Z_a}> a pub:OnDiskData ;
	
	\noindent \ \ dc:description "Data stored in file CDODiv2177686828992.txt" .
	
	\noindent:pandas a pub:Library ;
	
	\noindent \ \ dc:description "The pandas Python library" .

	\noindent:csv\_content\_2015\_11\_17T15\_16\_30Z a pub:InMemoryData ;
	
	\noindent \ \ dc:description "Data held by variable csv\_content" .	
\end{quotation}

Script item 4 is first rewritten as a \emph{assign} function call:
\begin{quotation}
	\noindent dd=operators.assign(csv\_content[['YearMonth','HDD','CDD']])
\end{quotation}
and then processed just like the previous script item and the following RDF triples will be generated:
\begin{quotation}
	\noindent:operators.assign\_2015\_11\_17T15\_16\_32Z a prov:Activity ;
	
	\noindent \ \ pub:language "Python" ;
	
	\noindent \ \ pub:code "dd = csv\_content[['YearMonth','HDD','CDD']]" ;
	
	\noindent \ \ dc:description "Assign expression csv\_content[['YearMonth','HDD','CDD']] to variable dd" ;
	
	\noindent \ \ prov:startedAtTime "2015-11-17T15:16:32+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent \ \ prov:endedAtTime "2015-11-17T15:16:32+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent \ \ prov:used <\url{http://example.org/csv_content%5B%5B%27YearMonth%27%2C%27HDD%27%2C%27CDD%27%5D%5D_2015_11_17T15_16_32Z_a}> .
		
	\noindent \ \ prov:generated :dd\_2015\_11\_17T15\_16\_32Z ;
	
	\noindent<\url{http://example.org/csv_content%5B%5B%27YearMonth%27%2C%27HDD%27%2C%27CDD%27%5D%5D_2015_11_17T15_16_32Z_a}> a pub:InMemoryData ;
		
	\noindent\ \ dc:description "Expression csv\_content[['YearMonth','HDD','CDD']]" .

	\noindent:dd\_2015\_11\_17T15\_16\_32Z a prov:Entity ;

	\noindent\ \ dc:description "Data or result held by variable dd" .
\end{quotation}
We see that the \emph{assign} function knows less about its activity type, argument and return value than the read\_csv function because it is more general: the right hand side of the assignment operation could be data to load or to transform, but also could be result instead of data, so the type of the activity and the usage of the argument are both unknown to the \emph{assign} function. The same uncertainty holds for the return value.

Script item 5 is also an assignment, which adds the following triples to \_\_PROV\_\_:
\begin{quotation}
	\noindent :operators.assign\_2015\_11\_17T15\_16\_35Z a prov:Activity ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "dd.loc[:,'Year'] = dd['YearMonth']//100" ;
	
	\noindent\ \ dc:description "Assign expression dd['YearMonth']//100 to variable dd" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:16:35+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:16:35+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:used <\url{http://example.org/dd%5B%27YearMonth%27%5D%2F%2F100_2015_11_17T15_16_35Z_a}> .
	
	\noindent\ \ prov:generated :dd\_2015\_11\_17T15\_16\_35Z ;
	
	\noindent<http://example.org/dd%5B%27YearMonth%27%5D%2F%2F100_2015_11_17T15_16_35Z_a> a pub:InMemoryData ;
	
	\noindent\ \ dc:description "Expression dd['YearMonth']//100" .
	
	\noindent:dd\_2015\_11\_17T15\_16\_35Z a prov:Entity ;
	
	\noindent\ \ dc:description "Data or result held by variable dd" .
\end{quotation}
The thing worth noticing here is that the data object of the left hand side, dd, gets recognized from the expression dd.loc[:,'Year'] by the cell magic function and its URI (:dd\_2015\_11\_17T15\_16\_35Z) gets recorded in the \_\_OBJDICT\_\_ dictionary, so that the consecutive uses of the dd object as a whole (as opposed to a part of it such as dd['YearMonth']) will point to this URI instead of creating new URIs as long as dd does not change during the course.

Script item 6 is a deletion operation, it is first converted into:
\begin{quotation}
	\noindent dd=operators.delete(dd,'YearMonth')
\end{quotation}
and then get executed as a function invocation. The following triples get generated:
\begin{quotation}
	\noindent :operators.delete\_2015\_11\_17T15\_16\_38Z a pub:Transformation ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "del dd['YearMonth']" ;
	
	\noindent\ \ dc:description "Delete dd['YearMonth']" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:16:38+00:00"\^{}\^{}xsd:dateTime .
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:16:38+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ pub:transformed :dd\_2015\_11\_17T15\_16\_35Z ;
	
	\noindent\ \ prov:generated :dd\_2015\_11\_17T15\_16\_38Z ;
	
	\noindent:dd\_2015\_11\_17T15\_16\_35Z a pub:InMemoryData ;

	\noindent\ \ dc:description "Variable dd" .

	\noindent:dd\_2015\_11\_17T15\_16\_38Z a pub:InMemoryData ;
	
	\noindent\ \ dc:description "Data held by variable dd" .
\end{quotation}
Since \emph{dd} is used as a whole in the rewritten \emph{delete} function invocation, its URI gets reused with the help of the \_\_OBJDICT\_\_ dictionary, then dd, as a generated data object, gets a fresh URI :dd\_2015\_11\_17T15\_16\_38Z.

Script items 7, 8 and 9 are all function invocations and generate the following triples:
\begin{quotation}
	\noindent:dt.group\_aggregate\_2015\_11\_17T15\_16\_40Z a pub:Transformation ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "dd\_year = dt.group\_aggregate(dd, 'Year', np.sum)" ;
	
	\noindent\ \ dc:description "Group data in data frame dd by key(s) 'Year' and aggregate by function np.sum to get data in dd\_year" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:16:40+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:16:40+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ pub:transformed :dd\_2015\_11\_17T15\_16\_38Z ;
	
	\noindent\ \ prov:used :numpy, :pandas .
	
	\noindent\ \ prov:generated :dd\_year\_2015\_11\_17T15\_16\_40Z ;
	
	\noindent:dd\_year\_2015\_11\_17T15\_16\_40Z a pub:InMemoryData ;
	
	\noindent\ \ dc:description "Data held by variable or expression dd\_year" .
	
	\noindent:numpy a pub:Library ;
	
	\noindent\ \ dc:description "The numpy Python library" .
	
	\noindent:dt.average\_2015\_11\_17T15\_16\_59Z a pub:Transformation ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "cdd\_avg = dt.average(dd\_year['CDD'][0:31])" ;
	
	\noindent\ \ dc:description "Get the average of data in list dd\_year['CDD'][0:31] and save it at cdd\_avg" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:16:59+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:16:59+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ pub:transformed <\url{http://example.org/dd_year%5B%27CDD%27%5D%5B0%3A31%5D_2015_11_17T15_16_59Z_a}> ;
		
	\noindent\ \ prov:used :numpy .
	
	\noindent\ \ prov:generated :cdd\_avg\_2015\_11\_17T15\_16\_59Z ;
	
	\noindent<\url{http://example.org/dd_year%5B%27CDD%27%5D%5B0%3A31%5D_2015_11_17T15_16_59Z_a}> a pub:InMemoryData ;

	\noindent\ \ dc:description "Data held by variable or expression dd\_year['CDD'][0:31]" .
	
	\noindent:cdd\_avg\_2015\_11\_17T15\_16\_59Z a pub:InMemoryData ;

	\noindent\ \ dc:description "Data held by variable or expression cdd\_avg" .
		
	\noindent:dt.average\_2015\_11\_17T15\_17\_01Z a pub:Transformation ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "hdd\_avg = dt.average(dd\_year['HDD'][0:31])" ;
	
	\noindent\ \ dc:description "Get the average of data in list dd\_year['HDD'][0:31] and save it at hdd\_avg" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:17:01+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:17:01+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ pub:transformed <\url{http://example.org/dd_year%5B%27HDD%27%5D%5B0%3A31%5D_2015_11_17T15_17_01Z_a}> ;
		
	\noindent\ \ prov:used :numpy .
	
	\noindent\ \ prov:generated :hdd\_avg\_2015\_11\_17T15\_17\_01Z ;
	
	\noindent<\url{http://example.org/dd_year%5B%27HDD%27%5D%5B0%3A31%5D_2015_11_17T15_17_01Z_a}> a pub:InMemoryData ;
	
	\noindent\ \ dc:description "Data held by variable or expression dd\_year['HDD'][0:31]" .
	
	\noindent:hdd\_avg\_2015\_11\_17T15\_17\_01Z a pub:InMemoryData ;
	
	\noindent\ \ dc:description "Data held by variable or expression hdd\_avg" .	
\end{quotation}

Script items 10 and 11 are two assignments and generate the following triples:
\begin{quotation}
	\noindent:operators.assign\_2015\_11\_17T15\_17\_03Z a prov:Activity ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "dd\_year.loc[:, 'HDD'] = dd\_year['HDD']/hdd\_avg*100-100" ;
	
	\noindent\ \ dc:description "Assign expression dd\_year['HDD']/hdd\_avg*100-100 to variable dd\_year" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:17:03+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:17:03+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:used <\url{http://example.org/dd_year%5B%27HDD%27%5D%2Fhdd_avg%2A100-100_2015_11_17T15_17_03Z_a}> .
		
	\noindent\ \ prov:generated :dd\_year\_2015\_11\_17T15\_17\_03Z ;
	
	\noindent<\url{http://example.org/dd_year%5B%27HDD%27%5D%2Fhdd_avg%2A100-100_2015_11_17T15_17_03Z_a}> a pub:InMemoryData ;
	
	\noindent\ \ dc:description "Expression dd\_year['HDD']/hdd\_avg*100-100" .
	
	\noindent:dd\_year\_2015\_11\_17T15\_17\_03Z a prov:Entity ;
	
	\noindent\ \ dc:description "Data or result held by variable dd\_year" .
	
	\noindent:operators.assign\_2015\_11\_17T15\_17\_05Z a prov:Activity ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "dd\_year.loc[:, 'CDD'] = dd\_year['CDD']/cdd\_avg*100-100" ;
	
	\noindent\ \ dc:description "Assign expression dd\_year['CDD']/cdd\_avg*100-100 to variable dd\_year" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:17:05+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:17:05+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:used <\url{http://example.org/dd_year%5B%27CDD%27%5D%2Fcdd_avg%2A100-100_2015_11_17T15_17_05Z_a}> .
		
	\noindent\ \ prov:generated :dd\_year\_2015\_11\_17T15\_17\_05Z ;
	
	\noindent<\url{http://example.org/dd_year%5B%27CDD%27%5D%2Fcdd_avg%2A100-100_2015_11_17T15_17_05Z_a}> a pub:InMemoryData ;
	
	\noindent\ \ dc:description "Expression dd\_year['CDD']/cdd\_avg*100-100" .

	\noindent:dd\_year\_2015\_11\_17T15\_17\_05Z a prov:Entity ;
	
	\noindent\ \ dc:description "Data held by variable or expression dd\_year",
\end{quotation}

Script item 12 is a procedure invocation. It is rewritten to:
\begin{quotation}
	\noindent ds.write\_csv(dd\_year, 'dd\_year.csv', namespace=\_\_NAMESPACE\_\_, textdict=\_\_TEXTDICT\_\_, uridict=\_\_URIDICT\_\_, provgraph=\_\_PROV\_\_)
\end{quotation}
The content of the dictionaries passed as arguments are the same as for the case of function invocations, but without the \emph{return} entries because procedures do not have return values. The write\_csv procedure knows that the dd\_year.csv file is the generated data object and generates the following RDF triples:
\begin{quotation}
	\noindent:ds.write\_csv\_2015\_11\_17T15\_17\_13Z a pub:Saving ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "ds.write\_csv(dd\_year, 'dd\_year.csv')" ;
	
	\noindent\ \ dc:description "Save data in dd\_year to file dd\_year.csv" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:17:13+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:17:13+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ pub:saved :dd\_year\_2015\_11\_17T15\_17\_05Z ;

	\noindent\ \ prov:used :pandas .
	
	\noindent\ \ prov:generated <\url{http://example.org/%27dd_year.csv%27_2015_11_17T15_17_13Z}> ;
	
	\noindent:dd\_year\_2015\_11\_17T15\_17\_05Z a pub:InMemoryData.
	
	\noindent\ \ dc:description "Data or result held by variable dd\_year" .
	
	\noindent<\url{http://example.org/%27dd_year.csv%27_2015_11_17T15_17_13Z}> a pub:OnDiskData ;
	
	\noindent\ \ dc:description "Data stored in file dd\_year.csv" .
\end{quotation}
The write\_csv procedure provided more specific descriptions of the dd\_year variable than the general assignment operation.

The last script item is again a function invocation, but this time it generates a result instead of a data object, as shown by the following RDF triples generated:
\begin{quotation}
	\noindent:dp.plot\_2015\_11\_17T15\_17\_22Z a pub:Visualization ;
	
	\noindent\ \ pub:language "Python" ;
	
	\noindent\ \ pub:code "fig = dp.plot(dd\_year, kind='bar', figsize=(20,10))" ;
	
	\noindent\ \ dc:description "Visualize data in dd\_year with the matplotlib.pyplot library" ;
	
	\noindent\ \ prov:startedAtTime "2015-11-17T15:17:22+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ prov:endedAtTime "2015-11-17T15:17:22+00:00"\^{}\^{}xsd:dateTime ;
	
	\noindent\ \ pub:visualized :dd\_year\_2015\_11\_17T15\_17\_05Z ;
	
	\noindent\ \ prov:used :matplotlib.pyplot, :pandas .
	
	\noindent\ \ prov:generated :fig\_2015\_11\_17T15\_17\_22Z ;
	
	\noindent:matplotlib.pyplot a pub:Library ;
	
	\noindent\ \ dc:description "The matplotlib.pyplot Python library" .
	
	\noindent:fig\_2015\_11\_17T15\_17\_22Z a pub:PublishedResult ;
	
	\noindent\ \ dc:description "Figure held by variable fig" .
\end{quotation}
To display the result figure in the Jupyter notebook, the user just needs to input the following lines in a new cell:
\begin{quotation}
\noindent\%pylab inline

\noindent fig
\end{quotation}
The user could also save the figure to a file with the following command:
\begin{quotation}
	\noindent fig.savefig('dd\_year.png')
\end{quotation}
To review the RDF triples in the store so far, the user just needs to input the following command:
\begin{quotation}
	\noindent print(\_\_PROV\_\_.serialize(format='n3'))
\end{quotation}
The above three code cells are examples of invoking operations without tracking provenance.
% front end -- Jupyter notebooks
%Jupyter Notebook is a strong candidate for the front end because it supports a lot of programming languages popular among scientists such as R and Python.
% provenance capturing mechanism: parse Jupyter notebooks to extract provenance and construct provenance graphs
%The file system provided by the operating system makes a store that is easy to manage.
% resulting provenance graph: reproducibility check, bad node search
%Sample provenance aware operators able to capture provenance for tables and figures in Chapter 4 of NCA 2014 report are implemented to complete the prototype.

%A special operator is implemented to retrieve provenance graphs previously saved. 

%We propose an objective evaluation measurement based on the Halstead complexity measures (\cite{halstead1977elements}, paraphrased in \cite{weyuker1988evaluating}), and we choose the task of data preparation for our evaluation. Data preparation loosely means indexing, organizing and optimizing data so they become structured in a form that 1) people can use and 2) software can consume. Figure~\ref{fig:data-analytics} shows how data preparation is related to other data analytics tasks\footnote{http://tw.rpi.edu/media/latest/DataAnalytics2015\_week1a.ppt [Retrived on May 11th, 2015]}. It is also called data munging and a sense of it could be obtained via reading any textbook talking about a data processing oriented programming language such as Perl \cite{cross2001data}.
%
%\begin{figure}
%	\centering
%	\includegraphics[width=\linewidth]{data-analytics.png}
%	\caption{Data analytics levels}
%	\label{fig:data-analytics}
%\end{figure}
%
%The basic idea is: provenance ontologies are used in software tools capturing provenance and reproducing the process of a certain task such as data preparation, so to evaluate the usability of such ontologies, we look at the complexity of software tools built on them. The less complex the software, the more usable the ontology.
%
%\begin{itemize}
%\item $\eta_1 = $Number of distinct operators.
%\item $\eta_2 = $Number of distinct operands.
%\item $N_1 = $Total number of operators.
%\item $N_2 = $Total number of operands.
%\end{itemize}
%%The program volume is defined to be
%%\begin{equation}
%%V = (N_1+N_2) \log_2(\eta_1+\eta_2).
%%\end{equation}
%An approximate formula for programming effort as a measure of program complexity is:
%\begin{equation}
%E = \frac{\eta_1N_2(N_1+N_2)\log_2(\eta_1+\eta_2)}{2\eta_2}.
%\end{equation}
%
%We choose the Halstead measure because the comparison of programming on top of different ontologies is mostly about the number and types of operations, rather than data flows (e.g., Oviedo in \cite{oviedo1993control} proposed a measure based on program data flows).
%
%We draw our data preparing operations from the R programming language. The assumption is that R is a data processing oriented programming language and the operations covered by R are typical for data processing.
%
%So the operations we are looking at are:
%\begin{itemize}
%	\item importing data from a file (be it a text file, an Excel spreadsheet, an XML file, or a netCDF file),
%	\item webscraping,
%	\item annotating datasets,
%	\item combining objects into a vector,
%	\item combining objects as columns or rows.
%\end{itemize}
%
%Currently we are picking typical data preparation tasks and describing them as combinations of the operations mentioned above. The plan is to calculate Halstead complexity values for programs based on PROV-PUB-O and directly on PROV-O for each hypothesis listed in the previous subsection to validate it.
%
%We originally planned to also describe the automatic provenance capturing mechanism and the proof-of-concept platform in this chapter. But the PROV-PUB-O part expands unexpectedly well and we decided to focus on it and move the other two sections to the future work chapter.

%\resetfootnote %this command starts footnote numbering with 1 again.

%\begin{figure}
%\centering
%\vspace{2.0in}
%\caption[A Shorter Caption for the List of Figures]
%   {This is the Caption for the First Figure in Chapter 2.  It is a
%    long, long caption; we do not want to put the whole thing in the
%    List of Figures. A Shorter Caption can go in the square brackets.}
% If you like additional lines in the caption indented, see the root template
% file rpithes.tex for an example of using the caption package to do this.
%\end{figure}
 
%This is shown in table~\ref{mytable}.  % see \label below
 
%\begin{table}
%\caption{This is the Caption for Table 2}
%\label{mytable}        % \label command must always comes AFTER the caption
%\begin{center}
%\begin{tabular}{lll}
%Here's       & another     & example  \\
%of           & a           & table    \\
%floated      & with        & the      \\
%\verb+table+ & environment & command.
%\end{tabular}
%\end{center}
%\end{table}


%\section{This is a Section Heading}
 
%\subsection{This is a Subsection Heading} 
 
%Text before a footnote.\footnote{Here's the text of the footnote.}
%Text after the footnote.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
