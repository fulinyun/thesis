%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                                                                 %
%                           RELATED WORK                          %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\chapter{RELATED WORK}
\label{related-work}
%\resetfootnote %this command starts footnote numbering with 1 again.

\section{General discussions on provenance and research reproducibility}
Jarvis in \cite{jarvis2010importance} talks about the importance of provenance in the context of journalism. 
%according to Tan et al \cite{tan2007provenance}, the provenance information discussed in this proposal falls into the category of workflow (or coarse-grained) provenance, where detailed transformation processes of specific pieces of data in the final publications are not captured. For example, the process of generating a table is captured, but not the process that leads to specific columns, rows or cells of the table, which includes data transformation details such as the aggregation function used and the deletion of outliers.

Donoho et al in \cite{donoho2009reproducible} pointed out that current computational science practice, unlike the well-established deductive science and empirical science, doesn't generate routinely verifiable knowledge due to the lack of mature responses to the ubiquity of error in science such as formal logic and mathematical proof for deduction, and statistical hypothesis testing and standardized reproducibility information for empiricism. Following Claerbout's idea that
\begin{quote}
	We publish not just computational results
	but also the complete software environment
	and data that generated those results.
\end{quote}
, Donoho et al developed the Wavelab package which contained a unified set of wavelet and time-frequency tools that reproduce all the calculations in the papers Donoho and his collaborators had written on computational harmonic analysis \cite{buckheit1995wavelab}. In \cite{donoho2009reproducible}, the authors mentioned that reproducible publication packages benefit \emph{strangers} who don't possess our current short-term memory and experiences.
\begin{quote}
	In the heat
	of a computational project, we store many things
	in short-term memory that we need at that moment
	to use the code productively.
\end{quote}
In other words, conducting research in a reproducible manner hurts productivity in the heat of a project, although years from now, we ourselves, not remembering the myriad small details that accumulated in our minds during this project, will become such strangers.

Gentleman and Lang in \cite{gentleman2007statistical} proposed the idea of a \emph{research compendium}. A compendium can include several \emph{dynamic documents} that are mixtures of text and code. They also implemented a prototype by using a modified version of the \texttt{noweb} markup \cite{ramsey1994literate} to write dynamic documents, writing text chunks in a modified version of \LaTeX and writing code in R. Dynamic documents are processed with Sweave \cite{leisch2002sweave} and compendiums are represented as R packages.

Other discussions to come after proposal... (or now:)

\section{Provenance capturing approaches}
\cite{groth2009recording} presents five characteristics of provenance information, namely immutable, meaning intact after creation, attributable, meaning clear responsibility, autonomously creatable, meaning created by the most appropriate agent, finalizable, meaning clear timing of completeness, and process reflecting, meaning able to reflect the whole process leading to the final product. It also presents the concept of p-assertions first defined in \cite{groth2006architecture} and the six key actors in provenance-aware systems, namely application, sender, receiver, asserter, recorder and provenance store.

\cite{miles2011prime} presents a provenance question driven methodology for provenance capturing.

Workflow systems such as VisTrails \cite{freire2014reproducibility}, Kepler \cite{ludascher2006scientific}, Taverna \cite{wolstencroft2013taverna} and ReproZip \cite{chirigati2013reprozip} will be discussed in detail in the final thesis.

\section{Provenance for research publications}
\subsection{Models for publication structure}
\cite{taboada2006rhetorical} covers rhetorical structure theory
\cite{groza2007salt} semantically annotates \LaTeX \ source files so that roles played by each part of the publication are made explicit.
\cite{clark2013micropublications} micropublications: a semantic model for claims, evidence, arguments and annotations in biomedical communications.
And more to come after proposal...

\subsection{Models for Publication Preparing Process}
PROV-O\footnote{http://www.w3.org/TR/prov-o/} and ProvONE\footnote{http://vcvcomputing.com/provone/provone.html} will be discussed later.

\section{Ontology usability evaluation}
Ontology usability evaluation is an aspect of the more general task of ontology evaluation. As mentioned in \ref{subsec:evaluation}, ontology evaluation starts with checking completeness and consistency of ontologies (e.g., \cite{gruninger1995methodology}), so called \emph{deductive approaches} in \cite{brank2005survey}.\comment{???} very few work has been done to compare ontologies in terms of how useful they are to certain tasks. 
the Severity Ratings for Usability Problems\footnote{http://www.nngroup.com/articles/how-to-rate-the-severity-of-usability-problems/ [Retrieved April 12th, 2015]}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
