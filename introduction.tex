\chapter{INTRODUCTION}
\label{introduction}
\section{What does provenance mean in this thesis}
According to Oxford English Dictionary, provenance is the chronology of the ownership, custody or 
location of a historical object. For digital artifacts, the Provenance Working Group of World Wide 
Web Consortium (W3C) defined provenance as \begin{quote}\textit{information about entities, activities, and 
people involved in producing a piece of data or thing, which can be used to form assessments about 
its quality, reliability or trustworthiness.}\end{quote} This thesis focuses on provenance for 
research publications, which are a kind of digital artifact, so in this thesis, the word 
\emph{provenance} means information about data, their stewardship activities, and agents involved in the 
production of results reported in research publications. Here \emph{data} may come from observations, 
model runs or repositories supporting data reuse; \emph{data stewardship activities} include semantical, 
syntactical and physical changes of data; \emph{agents} are people, organizations and software agents 
relevant to the data and their steward activities at any phase of the data lifecycle; \emph{results} 
are a special kind of objects derived from data that are the final products reported in research publications. Note that this definition 
of results deviates from the concept of \emph{scientific conclusions}, which are the insights the results try to support and thus are hard to model. Also note that information about the \emph{linkage} among these data, activities and agents are also implicitly included in provenance. For example, the fact of a data object \emph{being generated by} an activity could be captured as a link between the data object and the activity. Such linkage information is one of the major differences between provenance and separate descriptive metadata chunks.

Semantical changes of data mean the changes in the actual meaning of data, which is a combination of the content and the context. Looking at content or context alone may lead to wrong judgment about whether a piece of data have been semantically changed. For example, a number ``1'' changed to ``1000'' may not have been semantically changed because the former number represents quantity in kilogram and the latter in gram and thus the meaning of the number has not changed. It is a syntactical change instead.

Syntactical changes of data mean the changes in the structure of data. A typical example is changing 
data serialized in XML to JSON without changing the actual meaning of the data. This is especially important in Web-based usage as the transmission mechanisms, that is, serialization, requires conversion to a different structure.

Physical changes of data mean changes in locations, character encodings and accessibility of data. 
For example, data downloaded from an online source are the result of changing the locations of the 
original data (now they are in two places). When the location of a piece of textual data changes, the 
character encoding might change as well if the source and target storages follow different encoding 
schemes. Changes of data sharing permissions are a kind of physical changes that change the 
accessibility of data. 

This classification of changes of data is based on the semiotic framework proposed by Burton-Jones et al. See Table 2 in \cite{burton2005semiotic}.

All these changes are performed by agents, mostly software agents such as software tools, programs 
using library functions and command line scripts, through running software in command line, GUI or 
interactive mode, function invocations, and script running.

Information about people and organization agents tells the readers who owns, is responsible for, or 
should get credit for the publication and the data and software it used, which makes it possible to 
recognize and reward not only the publication authors, but also data and software producers. 
Recognition of these people or organizations benefits all researchers with better data and software 
\cite{parsons2010data, goble2014better}.

Useful information about software agents, other than their owners, responsible parties and 
contributors, falls into two categories. The first one is static information such as source code and 
documentation. This kind of information is needed for readers of the publications to understand and 
reuse the software to \emph{reproduce} the scientific conclusions. The second category of software 
agent information is dynamic information, i.e., information associated with activities these agents 
perform. Examples include their running environments such as library dependencies and system 
environment variable values, and configurations such as parameters and command line arguments, at 
each time they run, and the communication history of a certain interactive programming session. Such 
information plays an important role in \emph{replicating} computational experiments.

Note that the two words \emph{reproduce} and \emph{replicate} are used carefully here, whose meanings 
will be discussed in detail in the next section.


\section{Why is provenance important in scientific works}
With sufficiently rich provenance information, a piece of scientific work would have the following two 
desirable features, namely \emph{transparency} and \emph{reproducibility}. At the very basic level, 
provenance helps answer questions such as \emph{``What data are the reported results based on, and 
where does this piece of data come from''}, \emph{``Have the data been modified, in what ways''} 
\cite{davidson2008provenance}, which makes a piece of scientific work \emph{transparent}, meaning the 
readers have access to the knowledge of the data, their steward activities and associated agents. 
With richer provenance on data steward activities and software agents, readers have the ability to 
perform the same experiments carried out by the authors, making the work \emph{replicable}, meaning 
the same experiment can be carried out in a different lab, according to Goble's keynote presentation 
at ISMB/ECCB 2013. The final goal of provenance is to enable readers to carry out different 
experiments to validate the same scientific conclusion that the original experiment tries to justify, 
which is, according to \cite{drummond2009replicability}, \emph{reproducibility}.

The first feature, transparency, not only increases the trustworthiness of the scientific work by 
making the research process leading to the publication open to public scrutiny, but also reveals the 
work that would otherwise not be recognized, such as the development, configuration, integration and 
deployment of software for experiments \cite{goble2014better}.

Here \emph{replicability} and \emph{reproducibility} are defined as in 
\cite{drummond2009replicability}. In the last decade, the word \emph{reproducibility} pops up a lot 
in discussions about provenance. For example, 
%Altintas et al., in \cite{altintas2004kepler}, claims that scientific research is generally held to be of good provenance when it is documented in detail sufficient to allow reproducibility, and 
Boose et al., in \cite{boose2007ensuring}, pointed out that
\begin{quote}data sets are reliable when the process used to create them are reproducible and 
analyzable for defects.\end{quote}
Drummond pointed out in \cite{drummond2009replicability} that \emph{reproducibility} in the sense of 
carrying out the same experiments by different researchers should actually be called 
\emph{replicability}.

Schwab et al. in \cite{schwab2000making} argue that the readers can usually identify the parameter 
they want to modify, the input data that they want to exchange, or the source code that they want to 
inspect after analyzing the execution of the original experiment. Based on this argument, we believe 
that replications of experiments help readers to do different experiments. In fact, exact replication 
is impossible since the times of performing experiments must differ, so we treat replication as a 
special case of reproduction where readers perform really similar experiments as the original one the 
authors did.

In other words, reproducibility can be viewed as a spectrum of readers' increasing ability to perform 
more and more different experiments from the original one. Here is an example of a list of actions 
readers can take based on the original experiments, in the ascending order of reproducibility:
\begin{itemize}
\item parameter tuning
\item change of function application order
\item introduction of new functions
\item use of new source data
\item use of new scientific approach
\end{itemize}
We can see that provenance of the original experiment supports all these actions by providing the 
static and dynamic information of the software agents involved and the data used.
% \comment{treat replicability as a special case of reproducibility}
% from 2014-10-20-computational-vs-scientific-reproducibility.txt


% how difficult and anti-motivated its capturing is to the authors, stating the authoring workflow here. Say that currently authors lack both the ability and the motivation to capture provenance for their publications, given the currently available tools. 
\subsection{Pervasiveness of computational methods and lack of transparency in them}
Table~\ref{table:jasa} shows how many articles in June issues of Journal of the American Statistical Association (JASA), the flagship journal for statistical research in the United States, used computational methods, as well as how many of them made their code publicly available.
\begin{table}
	\centering
	\caption[Computational methods and code availability of JASA]{Number of articles using computational methods and their code availability in June issues of Journal of the American Statistical Association in 1996, 2006, 2009 and 2011. Courtesy Victoria Stodden.}
	\label{table:jasa}
	\begin{tabular}{r|cc}
		JASA June & Computational Articles & Code Publicly Available \\ 
		\hline 1996 & 9 of 20 & 0\% \\ 
		 2006 & 33 of 35 & 9\% \\ 
		 2009 & 32 of 32 & 16\% \\ 
		 2011 & 29 of 29 & 21\% \\  
	\end{tabular} 
\end{table}
We can see from the table that using computational methods is the trend. Virtually every article published at JASA in the past 5 years uses computational methods, but very few of them are exposing code to the public.
In her talk in 2011 \cite{stodden2011establishing}, the author argued that the lack of transparency is hurting the credibility of scientific research.

In the area of biomedical research, Bustin in \cite{bustin2015reproducibility} pointed out that there is increasing concern about the reliability of biomedical research, and a comment article plus a series of five articles published in the Lancet journal in early 2014 suggested that up to 85\% of research funding is wasted in unreliable research. The comment article introduces the series and discusses the consistent and colossal failure of initially promising research findings to translate into improvements in health care because of the many economic, political, social and cultural factors that influence researchers, funders, regulators, institutions and companies \cite{macleod2014biomedical}. 
%The first article in the series pointed out that the research studies supported by around US\$240 billion worldwide investment may have problems at the time funders decide what research to support, causing that much research does not lead to worthwhile achievements and that good research ideas do not yield the anticipated results \cite{chalmers2014increase}. 
The second article in the series highlights that an absence of detailed written protocols and poor documentation of
research is common and that inadequate emphasis is placed on recording of research decisions and on reproducibility of research \cite{ioannidis2014increasing}. 
%The third article discusses the modern approach to the regulation, governance, and management of biomedical research and emphasizes how inefficient management can easily compromise the interests of patients and the public \cite{salman2014increasing}. 
The fourth article points out that a large percentage of protocols, reports and datasets associated with health research are rarely available, and there is selective reporting of methods and results, which leads to the introduction of bias and wastes huge amounts of research funding \cite{chan2014increasing}. The final article reemphasizes the absolute requirements for accurate, exhaustive and transparent reporting and notes that although reporting guidelines are important, they are all much less adopted and adhered to than they should be \cite{glasziou2014reducing}. The editors of the series make the revolutionary suggestion that rather than using journal impact factors to assess academics, it might be more reasonable to judge the researchers' work with the rigorousness of methodology, the transparency of reporting and the reproducibility of results, which would of course facilitate the publication of more reliable and biologically relevant data.

Stodden in \cite{stodden2014enabling} pointed out that digital scholarly objects such as data and code have become essential for the effective communication of computational findings. Computations are frequently of such a complexity that an explanation sufficiently detailed to enable others to replicate the results is not possible in a typical scientific publication. A solution to this problem is to accompany the publication with the code and data that generated the results and communicate a \emph{research compendium} \cite{gentleman2007statistical}. However, the scientific community has not yet reached a stage where the communication of research compendiums is standard \cite{donoho2009reproducible}. A number of delicate regulatory and policy changes are essential to catalyze both scientific advancement and the development of applications and discoveries outside academia by making the data and code associated with scientific discoveries broadly available.

%\comment{review Gentleman 2007 and Donoho 2009}

The earliest work on research reproducibility we have found so far is in the after dinner talk by Jon Claerbout at National Research Council meeting on High Performance Computing in Seismology on October 2nd, 1994\footnote{Seventeen years of super computing and other problems in seismology. Available at http://sepwww.stanford.edu/sep/jon/nrc.html. Accessed on May 10th, 2015.}, where Claerbout stated his famous slogan ``in engineering, a published paper is an advertisement of scholarship'', which Buckheit and Donoho later paraphrased as 
\begin{quote}
	An article about computational science in a scientific publication is \emph{not} the
	scholarship itself, it is merely \emph{advertising} of the scholarship. The actual scholarship is the 
	complete software development environment and the complete set
	of instructions which generated the figures.
\end{quote}
in \cite{buckheit1995wavelab}, where they talked about why and how they
made their wavelet analysis MATLAB routines, namely WaveLab, publicly available as a humble step towards really reproducible research, and pointed out that
\begin{quote}
	to work in accordance with this goal, we must decide on a discipline
	of how we will structure our computational experiments. We must also then proselytize
	among others in our group to get them to adopt this discipline.
\end{quote}
Two decades have passed, ``this discipline'' seems still hindering the authors from recording the details of their computational experiments in such a manner that others can readily replicate their work.

\section{Why is it hard for the authors to record provenance}
The reasons include subjective and objective. On the subjective side, authors may consider the details of computational experiments non-essential to their work. They want readers to be inspired by their ideas instead of paying unnecessary attention to the details of the source code, but actually the additional materials in the form of source code and datasets rarely harm the readers by distracting them to minor details. On the objective side, recording provenance can be distracting and counter-productive to the authors due to its easy-to-miss characteristics as well as its diverse spatial and temporal distributions. This thesis will focus on alleviating the difficulty on this side.

It is a fallacy that the authors do not have the knowledge of everything happened during the process 
of the research work. The fact that they successfully got the reported results proves that they 
actually have, at certain times, all the knowledge of provenance that is sufficient for the 
replication of their work. Some pieces of the provenance are just so transient that if they do not 
get recorded at the right time, they get lost forever.

We will use the creation of a tabular summary of a dataset as our running example. Authors first use some 
download software package such as \emph{GNU Wget}\footnote{GNU Wget: https://www.gnu.org/software/wget/, accessed on November 24th, 2015.} to download the dataset from a certain place online, and then 
use some data analysis software package to generate meaningful data products from the dataset, 
followed by creating the summary table with some table making software package. During this process 
of table creation, we recognize more or less the following provenance pieces.
\begin{itemize}
\item What download software package was used, including its name, distribution and version.
\item Where the dataset was downloaded, including its URL.
\item When the dataset downloading activity started and ended.
\item Who executed the downloading operation.
\item The information about the data analysis software package used, including its API documentation.
\item The information about the data analysis operations performed, including functions called along 
with their argument values, and parameter values used. 
\item The time period of the data analysis activity.
\item Who analyzed the dataset.
\item The information about the table making software package.
\item The time period of making the summary table.
\item Who created the table.
\end{itemize}
Figure~\ref{prov-pieces} illustrates how these pieces of provenance information scatter all over the 
creation process of the summary table.
\begin{figure}
\centering
\includegraphics[scale=0.5]{prov-pieces}
\caption[Provenance for the creation of a table]{How provenance scatters throughout a table creation process. \texttt{wget} is used as an example of data download tools, \texttt{Calc} as an example of data analysis tools, and \texttt{LyX} as an example of table making tools.}
\label{prov-pieces}
\end{figure}
All these pieces of information can be captured by the authors if they are informed of the list of 
information items they need to record and they pay sufficient attention at certain time points where 
certain information pieces are available, but to capture them, the authors would spend time learning the list of necessary provenance items, and would quite often get 
distracted from their writing and table creation work. Given that doing research based on data is 
resource intensive and requires concentration, capturing provenance during writing brings no 
immediate benefit but lowers the productivity of the authors, so authors do not have incentives to 
record provenance unless they are required to do so. Even if they really would like to record all the 
details of the computational experiments they are carrying out, they are highly likely to miss some 
pieces of provenance that are not so obvious to and cannot be remembered later by human beings. 
%The benefit of having provenance information captured and properly stored comes later when some readers of the publication would like to better understand, validate and/or reproduce the published results, usually with an intention to use the result producing software for further research.

%So we see that provenance of research publication preparation shows its importance some time after 
%the publications have been created, although its importance has already been widely recognized by 
%readers and the future selves of authors. The problem is that provenance gets lost, piece by piece, 
%after the creation of publications, at a rate depending on how well the authors keep or memorize the 
%details of the publication preparation process.

\section{Possibility of developing tools to alleviate the situation}
\label{sec:possibility}
We argue that it is possible to develop tools to alleviate the situation that important provenance gets lost due to lack of awareness or timely capturing. These tools should have the following features.
\begin{itemize}
\item \emph{Knowledge of provenance.} i.e., they have the knowledge of provenance that is necessary to capture.
\item \emph{Automatic capturing mechanism.} i.e., they support a provenance capturing mechanism that requires very little explicit input from the authors.
\item \emph{Sufficient functionality.} i.e., they support a wide range of functions authors need to perform computational experiments and to prepare research publications.
\end{itemize}
We discuss the possibility of these tools based on the features they should have.

Knowledge of provenance could be encoded and stored in these tools, e.g., in the form of an ontology. 
Existing workflow systems that enable replications of computational experiments already have the 
necessary knowledge of provenance, which our tools could inherit.

The automatic capturing mechanism is possible to implement because information about data, their steward 
activities, and agents is all available, or could be adapted to become available to certain software 
agents, since most of the operations of the computational experiments the authors perform are carried 
out with software. (Exceptions include data being noted down or copied with a pen on a piece of paper, 
but even in this case, if the authors adapt to the use of software tools and input/copy data with such 
tools on the hard drive, the automatic capturing mechanism would apply.)

To be specific, we go over the 
listed provenance items in the running example mentioned above. 
\begin{itemize}
\item Information about the original data such as its download URL is known by the download software, 
because the software needs the URL to download the data. 
\item So is the starting and ending times of the downloading activity. 
\item The user account system knows who downloads the data. 
\item The API documentation of the data analysis software package is available as part of the software 
package. 
\item Information about software parameter values and function calls is known to the software agents who 
configure the software and invoke these functions. In the case where the users need to edit a 
configuration file to change software parameter values, a software agent that can do these edits with 
function invocations could be introduced, which knows the parameter values used for each function call.
\item The person, the software and the times related to the table making activity are known by the user 
account system and the table making software itself.
\end{itemize}
%We argue that only physical, syntactical and semantic changes of data are activities worth our attention. Data representation efforts such as making the summary table have nothing to do with replicating the final results, which is a special kind of data, thus creating the representations of results does not need to be included in the provenance of the results.

Sufficient functionality is guaranteed because provenance aware versions of the existing software based on proper domain ontologies that performs data steward activities can be developed. Such software has all the functions current authors need to produce research publications. (They are just using the provenance unaware existing software to prepare research publications now.) 

To wrap up, our provenance capturing tools are provenance aware versions of existing tools used by authors of research publications. These tools get the knowledge of necessary provenance needed from the domain ontologies, and capture provenance as the authors are using the software to prepare publications -- no need to ask the authors to explicitly note down anything they have done because all they have done are already captured at the time of doing.

\section{Contributions of the work in this thesis}
\label{sec:contribution}
The goal of the thesis is to design a paradigm of preparing research publications to overcome the problems associated with provenance capturing, namely lack of awareness of necessary provenance items and lack of incentive to capture provenance in a timely manner. The paradigm is to create publications with libraries that transparently capture the proper provenance information on a portable platform.

The proper provenance information to be captured is defined in an ontology designed to model the preparing process of research publications. Although there are general ontologies for provenance\footnote{PROV-O: The PROV Ontology. Available at http://www.w3.org/TR/prov-o/} and for publications and citations\footnote{Introduction to SPAR. Available at http://sempublishing.sourceforge.net/}, ontologies describing the process of publication preparation do not exist yet. The hypothesis to justify for this contribution is that the developed ontology is more useful than existing ontologies in the use case of modeling research publication preparation process.
%Unlike models for computational experiments, the ontology presented in this thesis pays special attention to the human factor in the process, which is a significant feature of the publication preparing process compared with the computational experiment workflows. The provenance capturing mechanism is driven by the ontology.
%capturing architectures and recording protocols developed for capturing provenance in computational experiments \cite{groth2006architecture, groth2009recording}\comment{find difference in our mechanism}, and ontologies for semantic

Transparent provenance capturing means the authors do not need to explicitly input provenance in order to record it, and they are allowed to work in their familiar computational environments. The capturing actions happen without interrupting the authors' ongoing work. The hypothesis to justify for this part of the work is that the specified mechanism is more useful than existing mechanisms such as creating workflows in capturing provenance for research publications.

A portable platform is a software package or a Web application that runs on some environment that is available on all the popular computational systems, such as a Java program which runs on the Java Virtual Machine, a Python program which runs with the Python interpreter, or a Web based application written in HTML, JavaScript and/or PHP scripts which runs on any of the mainstream Web browsers. Preparing research publications based entirely on a portable platform eliminates the necessity of capturing provenance down to the computer system level. Two desirable features for the platform are that 1) it should supply all the functions needed in creating research publications, and 2) these functions can be used in a way that is similar to the software packages the author is used to working with. To ensure the first feature, the platform needs to be extensible, better if it already has a strong development community to supply a plethora of evolving modules. The second feature requires that the platform supports popular interactive editing modes widely accepted in the research community. Examples include those seen in research software packages such as MATLAB and R. The hypothesis to justify for this part is that the implemented platform fulfills the requirements placed by the transparent provenance mechanism, so it really is a proof-of-concept prototype. 

To sum up, contributions of the work in this thesis are:
\begin{itemize}
\item the creation of an ontology for capturing provenance in the process of research publication preparation, along with an objective evaluation;
\item the specification of a provenance capturing framework driven by the ontology. The framework makes the provenance capturing actions transparent to the authors of research publications; and 
\item the implementation of a provenance aware publication preparing platform prototype that reflects most of the desired features for the specified provenance capturing mechanism.
\end{itemize}

%At the time of proposal, the focus will be on the design of the provenance capturing ontology and the evaluation method of it.

The remainder of this thesis is organized as follows. Chapter~\ref{related-work} discusses related work.
Chapter~\ref{research-approach} presents the research approach in detail. 
Chapter~\ref{ch:ontologies} lists the PROV-PUB-O ontology files.
Chapter ~\ref{ch:case-study} presents the details of the case study the thesis work is based on,
%Survey results justifying the effectiveness of the approach are given in Chapter \ref{survey-results}. 
%. Further discussions about this work and conclusions are given in Chapter \ref{discussions-and-conclusions}
and future work is discussed in Chapter~\ref{future-work}.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
